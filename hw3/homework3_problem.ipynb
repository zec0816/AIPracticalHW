{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作业三：图像理解————简单图像语义分割\n",
    "本次作业目的是让同学们体验基本的图像理解任务。\n",
    "环境依赖：\n",
    "- Python\n",
    "- jittor\n",
    "- tqdm\n",
    "- pillow\n",
    "\n",
    "需要完成的内容：\n",
    "- 补全TODO标记的内容\n",
    "- 试着自己调整网络结构以及各项网络参数，看看不同网络的效果。\n",
    "\n",
    "需要提交的内容：\n",
    "- 补全后的代码（.ipynb文件），只需要提交初始U-NET的版本。\n",
    "- `merged_val_img/`目录下的实验结果。提交5张图片即可。\n",
    "- 实验报告，包括调整网络结构对实验结果的影响等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[i 1122 15:16:25.934901 96 log.cc:351] Load log_sync: 1\u001b[m\n",
      "\u001b[38;5;2m[i 1122 15:16:25.938353 96 compiler.py:956] Jittor(1.3.10.0) src: /home/ubuntu/.local/lib/python3.10/site-packages/jittor\u001b[m\n",
      "\u001b[38;5;2m[i 1122 15:16:25.942656 96 compiler.py:957] g++ at /usr/bin/g++(11.4.0)\u001b[m\n",
      "\u001b[38;5;2m[i 1122 15:16:25.943340 96 compiler.py:958] cache_path: /home/ubuntu/.cache/jittor/jt1.3.10/g++11.4.0/py3.10.18/Linux-5.15.0-1xdd/AMDEPYC740224-xf1/4253/default\u001b[m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[i 1122 15:16:25.971524 96 install_cuda.py:96] cuda_driver_version: [12, 4]\u001b[m\n",
      "\u001b[38;5;2m[i 1122 15:16:25.972917 96 install_cuda.py:82] needed restart but not /home/ubuntu/miniconda3/envs/ai_course/bin/python ['-m', 'ipykernel_launcher', '--f=/run/user/1000/jupyter/runtime/kernel-v3ad958f1e7d1d9290284c4144a4de149e3cc1ef6d.json'], you can ignore this warning.\u001b[m\n",
      "\u001b[38;5;2m[i 1122 15:16:25.978317 96 __init__.py:412] Found /home/ubuntu/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc(12.2.140) at /home/ubuntu/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc.\u001b[m\n",
      "\u001b[38;5;2m[i 1122 15:16:25.983354 96 __init__.py:412] Found addr2line(2.38) at /usr/bin/addr2line.\u001b[m\n",
      "\u001b[38;5;2m[i 1122 15:16:26.121561 96 compiler.py:1013] cuda key:cu12.2.140_sm_86\u001b[m\n",
      "\u001b[38;5;2m[i 1122 15:16:26.605663 96 __init__.py:227] Total mem: 31.34GB, using 10 procs for compiling.\u001b[m\n",
      "\u001b[38;5;2m[i 1122 15:16:26.710428 96 jit_compiler.cc:28] Load cc_path: /usr/bin/g++\u001b[m\n",
      "\u001b[38;5;2m[i 1122 15:16:26.817277 96 init.cc:63] Found cuda archs: [86,]\u001b[m\n",
      "\u001b[38;5;2m[i 1122 15:16:27.062265 96 cuda_flags.cc:55] CUDA enabled.\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# 环境配置。\n",
    "import jittor as jt\n",
    "import jittor.nn as nn\n",
    "from jittor.dataset import Dataset\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "jt.flags.use_cuda = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型搭建\n",
    "本次实验中，我们选用U-NET作为分割模型。\n",
    "\n",
    "网络结构如下：\n",
    "![](imgs/UNET_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,1,320,280,]\n"
     ]
    }
   ],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \"\"\"Block模型初始化。\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): 模型的输入特征通道数。\n",
    "            out_channels (int): 模型的输出特征通道数。\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias= False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias= False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def execute(self, x):\n",
    "        \"\"\"Block模型执行\n",
    "\n",
    "        Args:\n",
    "            x (jt.Var): 尺寸[N, in_channels, H, W]\n",
    "\n",
    "        Returns:\n",
    "            jt.Var: 尺寸[N, out_channels, H, W]\n",
    "        \"\"\"\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNET(nn.Module):\n",
    "    def __init__(self, in_channels: int=3, out_channels: int=1, features: List=[64,128,256,512]):\n",
    "        \"\"\"UNET初始化\n",
    "\n",
    "        Args:\n",
    "            in_channels (int, optional): 图像通道数. 默认为3.\n",
    "            out_channels (int, optional): 输出结果通道数. 默认为1.\n",
    "            features (List, optional): 中间层特征通道数. 默认为 [64,128,256,512].\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.down = nn.ModuleList()\n",
    "        self.up = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        for feature in features:\n",
    "            self.down.append(Block(in_channels, feature))\n",
    "            in_channels=feature\n",
    "        for feature in reversed(features):\n",
    "            self.up.append(\n",
    "                nn.ConvTranspose2d(feature*2, feature, 2, 2)\n",
    "            )\n",
    "            self.up.append(\n",
    "                Block(feature*2, feature) # x gets concat to 2xchannel\n",
    "            )\n",
    "        self.bottleneck = Block(features[-1], features[-1]*2)\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, 1)\n",
    "\n",
    "    def execute(self, x):\n",
    "        \"\"\"UNET前向\n",
    "\n",
    "        Args:\n",
    "            x (jt.Var): 输入图像，尺寸[N, in_channels, H, W]\n",
    "\n",
    "        Returns:\n",
    "            jt.Var: 输出图像，尺寸[N, out_channels, H, W]\n",
    "        \"\"\"\n",
    "        skip_connections = []\n",
    "        for down in self.down:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        for idx in range(0, len(self.up), 2):\n",
    "            x = self.up[idx](x)\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = nn.resize(x, size=skip_connection.shape[2:], mode='bicubic')\n",
    "            concat_skip = jt.concat((skip_connection, x), dim=1) # Concat along channels (b, c, h, w)\n",
    "            x = self.up[idx+1](concat_skip)\n",
    "        return self.final_conv(x)\n",
    "\n",
    "# 构建模型\n",
    "model = UNET()\n",
    "\n",
    "# 验证模型输入输出尺寸\n",
    "dummy_input = jt.random((2, 3, 320, 280))\n",
    "dummy_output = model(dummy_input)\n",
    "print(dummy_output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集\n",
    "\n",
    "我们使用[Carvana](https://www.kaggle.com/datasets/ipythonx/carvana-image-masking-png)作为实验数据集。\n",
    "这个数据集是一个较为简单的车辆分割数据集，包含不同类型、不同朝向的车辆。\n",
    "\n",
    "数据集下载网站：https://www.kaggle.com/datasets/ipythonx/carvana-image-masking-png\n",
    "\n",
    "数据集下载后会有`train_images`和`train_masks`两个目录，其中`train_images`中为训练数据，`train_masks`为Ground Truth。\n",
    "\n",
    "我们将数据集分为训练集和验证集两个部分。这两个部分的图像分别保存在`train.txt`和`val.txt`中。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509\n",
      "508\n",
      "[9,3,360,480,] [9,1,360,480,]\n",
      "[1,3,360,480,] [1,1,360,480,]\n"
     ]
    }
   ],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_path, mask_path, label_path=None, use_aug=False,\n",
    "                 batch_size=16, num_workers=2, shuffle=False):\n",
    "        \"\"\"初始化数据集\n",
    "\n",
    "        Args:\n",
    "            image_path (str): 图像路径\n",
    "            mask_path (str): 分割掩码标注路径\n",
    "            label_path (str): 图像集合文件路径。文件中每一行代表一张图像的名称\n",
    "            use_aug (bool, optional): 是否使用数据增强.\n",
    "            batch_size (int, optional): 图像批次N.\n",
    "            num_workers (int, optional): 并行工作进程数量.\n",
    "            shuffle (bool, optional): 是否随机顺序\n",
    "        \"\"\"\n",
    "        super().__init__(batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "        assert label_path is not None\n",
    "        with open(label_path, \"r\") as f:\n",
    "            names = f.readlines()\n",
    "        images, masks = [], []\n",
    "        # TODO(1): 计算所有图像的路径\n",
    "        # 假设image_path为'/data/image', mask_path为'/data/mask',\n",
    "        # 则images应为['/data/image/name1.jpg', '/data/image/name2.jpg', ...]\n",
    "        # 则masks应为['/data/mask/name1.png', '/data/mask/name2.png', ...]\n",
    "        # 其中name1, name2, ... 为 label_path中读到的测例名称names。\n",
    "        # Your code starts here\n",
    "        for line in names:\n",
    "            name = line.strip()\n",
    "            if name == \"\":\n",
    "                continue\n",
    "\n",
    "            images.append(os.path.join(image_path, name + \".jpg\"))\n",
    "            masks.append(os.path.join(mask_path, name + \".png\"))\n",
    "        # Your code ends here\n",
    "\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.use_aug = use_aug\n",
    "        self.total_len = len(self.images)\n",
    "\n",
    "    def apply_aug(self, image, mask):\n",
    "        \"\"\"随机数据增强\n",
    "\n",
    "        Args:\n",
    "            image (Image.Image): 图像\n",
    "            mask (Image.Image): 分割掩码\n",
    "\n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray]: 增强后的图像和分割掩码\n",
    "        \"\"\"\n",
    "        if random.random() < 0.7:\n",
    "            # TODO(2): 将图像和分割掩码水平翻转\n",
    "            # 提示：使用 Image.FLIP_LEFT_RIGHT\n",
    "            # Your code starts here\n",
    "            image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            mask = mask.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            # Your code ends here\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            # TODO(3): 将图像和分割掩码竖直翻转\n",
    "            # 提示：使用 Image.FLIP_TOP_BOTTOM\n",
    "            # Your code starts here\n",
    "            image = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "            mask = mask.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "            # Your code ends here\n",
    "        return image, mask\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"获取编号为index的数据\n",
    "\n",
    "        Args:\n",
    "            index (int): 编号\n",
    "\n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray]: 图像和掩码 尺寸分别为[3, 360, 480], [1, 360, 480]\n",
    "        \"\"\"\n",
    "        image = np.array(Image.open(self.images[index]).convert('RGB'))\n",
    "        mask = np.array(Image.open(self.masks[index]))\n",
    "        mask[mask == 255.0] = 1.0\n",
    "\n",
    "        # preprocess\n",
    "        image = Image.fromarray(image).resize((480, 360), resample=Image.BILINEAR)\n",
    "        mask = Image.fromarray(mask).resize((480, 360), resample=Image.NEAREST)\n",
    "        if self.use_aug:\n",
    "            image, mask = self.apply_aug(image, mask)\n",
    "\n",
    "        # Image读取的图像一般排列为[H, W, C]，而神经网络中图像一般排列为[C, H, W]\n",
    "        image = jt.array(np.transpose(image, (2, 0, 1)), dtype=jt.float32)\n",
    "        mask = jt.unsqueeze(jt.array(mask, dtype=jt.float32), 0)\n",
    "        return image, mask\n",
    "\n",
    "# 数据集路径设置\n",
    "image_path = 'train_images'\n",
    "mask_path = 'train_masks'\n",
    "train_label = './train.txt'\n",
    "val_label = './val.txt'\n",
    "\n",
    "# 训练集需要数据增强\n",
    "train_dataset = SegmentationDataset(\n",
    "    image_path, mask_path, train_label, use_aug=True,\n",
    "    batch_size=9, num_workers=2, shuffle=True,\n",
    ")\n",
    "# 验证集\n",
    "val_dataset = SegmentationDataset(\n",
    "    image_path, mask_path, val_label, use_aug=False,\n",
    "    batch_size=1, num_workers=2, shuffle=False,\n",
    ")\n",
    "\n",
    "# 检查数据集构建是否正确\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "for image, mask in train_dataset:\n",
    "    print(image.shape, mask.shape)\n",
    "    break\n",
    "for image, mask in val_dataset:\n",
    "    print(image.shape, mask.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型的训练与评估\n",
    "本次实验中我们使用AdamW优化器训练模型。默认训练轮数为8轮，可能需要训练30分钟以上。同学们调试代码时可以减少训练轮数以加快训练。\n",
    "\n",
    "我们采用两个标准来评估模型，acc和dice score。这两个指标均为逐像素指标。\n",
    "\n",
    "假设$P_i$为图像$i$预测掩码，$G_i$为图像$i$的实际掩码，$N$为图像总数，$Count(x)$表示计算掩码$x$中1的数量，$Size(x)$表示计算掩码$x$中像素总数， 则acc的计算标准为：\n",
    "$$\n",
    "    acc=(\\sum_{i} \\frac{Count(P_i == G_i)}{Size(G_i)}) / N\n",
    "$$\n",
    "dice score的计算标准为：\n",
    "$$\n",
    "    score=(\\sum_{I} \\frac{2 \\times Count(P_i * G_i)}{Count(P_i) + Count(G_i)}) / N\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/509 [00:00<?, ?it/s]\n",
      "Compiling Operators(2/2) used: 4.31s eta:    0s \n",
      "  0%|          | 1/509 [00:04<36:51,  4.35s/it]\n",
      "Compiling Operators(1/34) used: 3.32s eta:  110s 6/34) used: 5.33s eta: 24.9s 9/34) used: 6.33s eta: 17.6s 10/34) used: 7.33s eta: 17.6s 11/34) used: 8.34s eta: 17.4s 13/34) used: 9.34s eta: 15.1s 18/34) used: 10.3s eta:  9.2s 19/34) used: 11.4s eta: 8.96s 24/34) used: 12.4s eta: 5.15s 26/34) used: 13.4s eta: 4.11s 29/34) used: 14.4s eta: 2.48s 30/34) used: 15.4s eta: 2.05s 32/34) used: 16.4s eta: 1.02s 33/34) used: 16.4s eta: 0.497s 34/34) used: 40.4s eta:    0s \n",
      "  0%|          | 2/509 [00:50<4:04:18, 28.91s/it]\n",
      "Compiling Operators(3/3) used: 4.31s eta:    0s \n",
      "100%|██████████| 509/509 [04:14<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 0\n",
      "saving model...\n",
      "model saved.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 508/508 [00:42<00:00, 11.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 0: val_acc=95.78699210262674, val_dice_score=0.8799901075951495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 509/509 [03:15<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 1\n",
      "saving model...\n",
      "model saved.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 508/508 [00:09<00:00, 53.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 1: val_acc=62.76139148224996, val_dice_score=0.5343483091466725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 509/509 [03:16<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 2\n",
      "saving model...\n",
      "model saved.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 508/508 [00:09<00:00, 53.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 2: val_acc=99.19457406274915, val_dice_score=0.982086423369237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'epoch_best.jt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def training(model:UNET, data_loader:SegmentationDataset, optimizer:jt.optim.AdamW, epoch_id:int):\n",
    "    \"\"\"进行一轮训练\n",
    "\n",
    "    Args:\n",
    "        model (UNET): 待训练模型\n",
    "        data_loader (SegmentationDataset): 数据集\n",
    "        optimizer (jt.optim.AdamW): 优化器\n",
    "        epoch_id (int): 当前轮数\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    loss_func = nn.binary_cross_entropy_with_logits\n",
    "    for batch in tqdm(data_loader):\n",
    "        x, y = batch\n",
    "        pred = model(x)\n",
    "        # TODO(4): 训练模型：\n",
    "        # 可以参考作业二的实现。\n",
    "        # Your code starts here\n",
    "        loss = loss_func(pred, y)\n",
    "        optimizer.step(loss)\n",
    "        # Your code ends here\n",
    "\n",
    "    # 保存模型\n",
    "    print(f\"Training Epoch {epoch_id}\")\n",
    "    print(\"saving model...\")\n",
    "    jt.save(model.state_dict(), 'epoch_{}.jt'.format(epoch_id))\n",
    "    print(\"model saved.\\n\")\n",
    "\n",
    "def validation(model:UNET, data_loader:SegmentationDataset, epoch_id:int):\n",
    "    \"\"\"进行一轮验证\n",
    "\n",
    "    Args:\n",
    "        model (UNET): 待验证模型\n",
    "        data_loader (SegmentationDataset): 数据集\n",
    "        epoch_id (int): 当前轮数\n",
    "\n",
    "    Returns:\n",
    "        float: 当前模型的dice score\n",
    "    \"\"\"\n",
    "    sum_acc, sum_dice_score, num_imgs = 0, 0, 0\n",
    "    \n",
    "    model.eval()\n",
    "    for batch in tqdm(data_loader):\n",
    "        x, y = batch\n",
    "        pred = model(x)\n",
    "\n",
    "        pred = jt.sigmoid(pred)\n",
    "        pred = (pred > 0.5).float()\n",
    "        # TODO(5): 计算模型评估指标\n",
    "        # sum_acc为所有图像的acc之和，sum_dice_score为所有图像的dice_score之和，num_imgs为图像总数\n",
    "        # Your code starts here\n",
    "        b = pred.shape[0]\n",
    "        for i in range(b):\n",
    "            p = pred[i]\n",
    "            gt = y[i]\n",
    "            acc = (p == gt).float().mean().item()\n",
    "            inter = (p * gt).sum().item()\n",
    "            p_sum = p.sum().item()\n",
    "            g_sum = gt.sum().item()\n",
    "            dice = (2.0 * inter) / (p_sum + g_sum + 1e-6)\n",
    "            sum_acc += acc\n",
    "            sum_dice_score += dice\n",
    "            num_imgs += 1\n",
    "        # Your code ends here\n",
    "\n",
    "    if num_imgs == 0:\n",
    "        print(\"No validation images found!\")\n",
    "        return 0.0\n",
    "    \n",
    "    print(f\"Validation Epoch {epoch_id}: val_acc={sum_acc/num_imgs * 100}, val_dice_score={sum_dice_score / num_imgs}\")\n",
    "    return sum_dice_score / num_imgs\n",
    "\n",
    "# 总训练轮数。可以根据算力调整。\n",
    "num_epochs = 3\n",
    "best_score, best_epoch = 0, 0\n",
    "optimizer = jt.optim.AdamW(params = model.parameters(), lr = 1.5e-3, weight_decay=0.3)\n",
    "for epoch_id in range(num_epochs):\n",
    "    training(model, train_dataset, optimizer, epoch_id=epoch_id)\n",
    "    score = validation(model, val_dataset, epoch_id=epoch_id)\n",
    "    # 记录dice score最高轮\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_epoch = epoch_id\n",
    "shutil.copyfile('epoch_{}.jt'.format(best_epoch), 'epoch_best.jt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图像分割的可视化\n",
    "我们在验证集上选取部分图像生成可视化结果，用以直观查看模型的能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_with_mask(image:jt.Var, mask:jt.Var, fp:str):\n",
    "    \"\"\"叠放分割Mask和图像。\n",
    "\n",
    "    Args:\n",
    "        image (jt.Var): 图像，尺寸为(3, H, W)\n",
    "        mask (jt.Var): 分割掩码，尺寸为(1, H, W)\n",
    "        fp (str): 保存图像路径\n",
    "    \"\"\"\n",
    "    nimage = jt.permute(jt.clamp(image, 0, 255), (1, 2, 0))\n",
    "    nmask = jt.zeros_like(nimage)\n",
    "    nmask[:, :, :1] = jt.permute(jt.clamp(mask * 255 + 0.5, 0, 255), (1, 2, 0))\n",
    "    im = np.asarray((nimage * 0.4 + nmask * 0.6).numpy(), dtype=np.uint8)\n",
    "    im = Image.fromarray(im)\n",
    "    im.save(fp)\n",
    "\n",
    "def save_images(model:UNET, loader:SegmentationDataset, folder:str='val_img'):\n",
    "    \"\"\"可视化数据集中部分图像的分割结果\n",
    "\n",
    "    Args:\n",
    "        model (UNET): 模型\n",
    "        loader (SegmentationDataset): 数据集\n",
    "        folder (str, optional): 保存路径.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    if not os.path.isdir(folder):\n",
    "        os.mkdir(folder)\n",
    "    for idx, (x, y) in enumerate(loader):\n",
    "        with jt.no_grad():\n",
    "            preds = jt.sigmoid(model(x))\n",
    "            preds = (preds > 0.5).float()\n",
    "        save_image_with_mask(x[0], preds[0], os.path.join(folder, f\"pred_{idx}.png\"))\n",
    "        save_image_with_mask(x[0], y[0], os.path.join(folder, f\"mask_{idx}.png\"))\n",
    "        if idx >= 4:\n",
    "            break\n",
    "\n",
    "def get_concat_v(im1:Image.Image, im2:Image.Image):\n",
    "    \"\"\"将两张图像合并为一张\n",
    "\n",
    "    Args:\n",
    "        im1 (Image.Image): 上方图像\n",
    "        im2 (Image.Image): 下方图像\n",
    "\n",
    "    Returns:\n",
    "        Image.Image: 合并后的图像\n",
    "    \"\"\"\n",
    "    # TODO(6): 将两张图像合并为一张。\n",
    "    # Your code starts here\n",
    "    w1, h1 = im1.size\n",
    "    w2, h2 = im2.size\n",
    "    dst_w = max(w1, w2)\n",
    "    dst_h = h1 + h2\n",
    "    mode = im1.mode\n",
    "    if mode != im2.mode:\n",
    "        im1 = im1.convert('RGB')\n",
    "        im2 = im2.convert('RGB')\n",
    "        mode = 'RGB'\n",
    "    dst = Image.new(mode, (dst_w, dst_h))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (0, h1))\n",
    "    # Your code ends here\n",
    "    return dst\n",
    "\n",
    "def merge_photos(src_folder: str='./val_img', dst_folder: str='./merged_val_img', remove_single: bool=True):\n",
    "    \"\"\"将预测结果和Ground Truth对比。\n",
    "\n",
    "    Args:\n",
    "        src_folder (str, optional): 源图像路径\n",
    "        dst_folder (str, optional): 目标图像路径\n",
    "        remove_single (bool, optional): 是否删除源图像\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for fname in os.listdir(src_folder):\n",
    "        if fname.endswith('.png'):\n",
    "            files.append(os.path.join(src_folder, fname))\n",
    "    if not os.path.isdir(dst_folder):\n",
    "        os.mkdir(dst_folder)\n",
    "    for i in range(int(len(files)/2)):\n",
    "        pred_img = Image.open(f'{src_folder}/pred_{i}.png')\n",
    "        mask_img = Image.open(f'{src_folder}/mask_{i}.png')\n",
    "        get_concat_v(pred_img, mask_img).save(f'{dst_folder}/merged_pred_mask_{i}.png')\n",
    "        if remove_single:\n",
    "            os.remove(f'./val_img/pred_{i}.png')\n",
    "            os.remove(f'./val_img/mask_{i}.png')\n",
    "\n",
    "model.load_state_dict(jt.load('epoch_best.jt'))\n",
    "save_images(model, val_dataset)\n",
    "merge_photos()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
