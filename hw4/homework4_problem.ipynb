{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作业四：图像生成\n",
    "本次作业目的是让同学们体验使用GAN模型进行图像生成，训练一个随机噪声和类别标签映射为数字图片的Conditional GAN模型，并由自己的学号生成一个手写数字序列\n",
    "\n",
    "需要完成的内容\n",
    "- 补全TODO标记的内容\n",
    "- 试着自己调整网络结构、损失函数等，看看不同网络的效果。\n",
    "\n",
    "需要提交的内容\n",
    "- 补全后的代码（.ipynb文件），只需要提交初始版本。\n",
    "- 实验报告，要求包含生成的数字序列和简单的实验总结。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i 1126 08:50:45.458430 12 lock.py:85] Create lock file:/root/.cache/jittor/jt1.3.10/g++12.4.0/py3.8.20/Linux-5.15.0-1x1f/AMDEPYC740224-xf1/176f/jittor.lock\n",
      "[i 1126 08:50:45.486219 12 compiler.py:956] Jittor(1.3.10.0) src: /root/miniconda3/envs/ai_course/lib/python3.8/site-packages/jittor\n",
      "[i 1126 08:50:45.498048 12 compiler.py:957] g++ at /usr/bin/g++(12.4.0)\n",
      "[i 1126 08:50:45.498230 12 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++12.4.0/py3.8.20/Linux-5.15.0-1x1f/AMDEPYC740224-xf1/176f/default\n",
      "[i 1126 08:50:45.555791 12 install_cuda.py:96] cuda_driver_version: [12, 4]\n",
      "[i 1126 08:50:45.556529 12 install_cuda.py:82] needed restart but not /root/miniconda3/envs/ai_course/bin/python ['-m', 'ipykernel_launcher', '--f=/root/.local/share/jupyter/runtime/kernel-v3197ecc5983828c8616e31aa963fde2545ef4c3fd.json'], you can ignore this warning.\n",
      "[i 1126 08:50:45.584734 12 __init__.py:412] Found /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc(12.2.140) at /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc.\n",
      "[i 1126 08:50:45.604554 12 __init__.py:412] Found addr2line(2.42) at /usr/bin/addr2line.\n",
      "[i 1126 08:50:45.822618 12 compiler.py:1013] cuda key:cu12.2.140_sm_89\n",
      "[i 1126 08:50:45.995457 12 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.10/g++12.4.0/py3.8.20/Linux-5.15.0-1x1f/AMDEPYC740224-xf1/176f/default/cu12.2.140_sm_89\n",
      "[i 1126 08:50:46.016040 12 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.10/g++12.4.0/py3.8.20/Linux-5.15.0-1x1f/AMDEPYC740224-xf1/176f/default/cu12.2.140_sm_89/jit\n",
      "[i 1126 08:50:46.017196 12 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.10/g++12.4.0/py3.8.20/Linux-5.15.0-1x1f/AMDEPYC740224-xf1/176f/default/cu12.2.140_sm_89/obj_files\n",
      "[i 1126 08:50:46.017423 12 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.10/g++12.4.0/py3.8.20/Linux-5.15.0-1x1f/AMDEPYC740224-xf1/176f/default/cu12.2.140_sm_89/gen\n",
      "[i 1126 08:50:46.017670 12 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.10/g++12.4.0/py3.8.20/Linux-5.15.0-1x1f/AMDEPYC740224-xf1/176f/default/cu12.2.140_sm_89/tmp\n",
      "[i 1126 08:50:46.017916 12 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.10/g++12.4.0/py3.8.20/Linux-5.15.0-1x1f/AMDEPYC740224-xf1/176f/default/cu12.2.140_sm_89/checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[i 1126 08:50:53.657409 64 log.cc:351] Load log_sync: 1\u001b[m\n",
      "\u001b[38;5;2m[i 1126 08:51:09.576121 64 __init__.py:227] Total mem: 503.72GB, using 16 procs for compiling.\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling jittor_core(150/151) used: 24.183s eta: 0.161s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[i 1126 08:51:44.523009 64 log.cc:351] Load log_sync: 1\u001b[m\n",
      "\u001b[38;5;2m[i 1126 08:51:44.524679 64 jit_compiler.cc:28] Load cc_path: /usr/bin/g++\u001b[m\n",
      "\u001b[38;5;2m[i 1126 08:51:44.832990 64 init.cc:63] Found cuda archs: [89,]\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling jittor_core(151/151) used: 34.515s eta: 0.000s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[i 1126 08:51:44.890815 64 compile_extern.py:388] Downloading cutt...\u001b[m\n",
      "\u001b[38;5;2m[i 1126 08:51:44.930172 64 compile_extern.py:401] installing cutt...\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling libcutt(8/9) used: 5.174s eta: 0.647s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[i 1126 08:51:54.729531 64 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.10/g++12.4.0/py3.8.20/Linux-5.15.0-1x1f/AMDEPYC740224-xf1/176f/default/cu12.2.140_sm_89/custom_ops\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling libcutt(9/9) used: 9.687s eta: 0.000s\n",
      "Compiling gen_ops_mkl_conv_backward_x_mkl_conv_backward_w_mk___hashbc87cd(6/7) used: 2.970s eta: 0.495s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[i 1126 08:51:59.896417 64 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.10/g++12.4.0/py3.8.20/Linux-5.15.0-1x1f/AMDEPYC740224-xf1/176f/default/cu12.2.140_sm_89/cuda\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling gen_ops_mkl_conv_backward_x_mkl_conv_backward_w_mk___hashbc87cd(7/7) used: 3.255s eta: 0.000s\n",
      "Compiling gen_ops_cub_where_cub_test_cub_cumsum_cub_arg_redu___hash7af395(6/6) used: 2.232s eta: 0.000s\n",
      "Compiling gen_ops_cudnn_rnn_cudnn_conv3d_cudnn_rnn_backward____hash4a5ca9(16/16) used: 5.417s eta: 0.000s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[i 1126 08:52:16.794983 64 cuda_flags.cc:55] CUDA enabled.\u001b[m\n"
     ]
    }
   ],
   "source": [
    "import jittor as jt\n",
    "from jittor import init\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from jittor import nn\n",
    "\n",
    "jt.flags.use_cuda = 1\n",
    "\n",
    "# number of epochs of training\n",
    "n_epochs = 10\n",
    "# size of the batches\n",
    "batch_size = 16\n",
    "# adam: learning rate\n",
    "lr = 0.0002\n",
    "# adam: decay of first order momentum of gradient\n",
    "b1 = 0.5\n",
    "# adam: decay of second order momentum of gradient\n",
    "b2 = 0.999\n",
    "# number of cpu threads to use during batch generation\n",
    "n_cpu = 8\n",
    "# dimensionality of the latent space\n",
    "latent_dim = 100\n",
    "# number of classes for dataset\n",
    "n_classes = 10\n",
    "# size of each image dimension\n",
    "img_size = 32\n",
    "# number of image channels\n",
    "channels = 1\n",
    "# interval between image sampling\n",
    "sample_interval = 10000\n",
    "\n",
    "# 图像尺寸\n",
    "img_shape = (channels, img_size, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.label_emb = nn.Embedding(n_classes, n_classes)\n",
    "        # nn.Linear(in_dim, out_dim)表示全连接层\n",
    "        # in_dim：输入向量维度\n",
    "        # out_dim：输出向量维度\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2))\n",
    "            return layers\n",
    "        self.model = nn.Sequential(*block((latent_dim + n_classes), 128, normalize=False), \n",
    "                                   *block(128, 256), \n",
    "                                   *block(256, 512), \n",
    "                                   *block(512, 1024), \n",
    "                                   nn.Linear(1024, int(np.prod(img_shape))), \n",
    "                                   nn.Tanh())\n",
    "\n",
    "    def execute(self, noise, labels):\n",
    "        gen_input = jt.contrib.concat((self.label_emb(labels), noise), dim=1)\n",
    "        img = self.model(gen_input)\n",
    "        # 将img从1024维向量变为32*32矩阵\n",
    "        img = img.view((img.shape[0], *img_shape))\n",
    "        return img\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.label_embedding = nn.Embedding(n_classes, n_classes)\n",
    "        self.model = nn.Sequential(nn.Linear((n_classes + int(np.prod(img_shape))), 512), \n",
    "                                   nn.LeakyReLU(0.2), \n",
    "                                   nn.Linear(512, 512), \n",
    "                                   nn.Dropout(0.4), \n",
    "                                   nn.LeakyReLU(0.2), \n",
    "                                   nn.Linear(512, 512), \n",
    "                                   nn.Dropout(0.4), \n",
    "                                   nn.LeakyReLU(0.2), \n",
    "                                   # TODO(1): 添加最后一个线性层，最终输出为一个实数\n",
    "                                   # Your code starts here\n",
    "                                   nn.Linear(512, 1),\n",
    "                                   nn.Sigmoid()\n",
    "                                   # Your code ends here\n",
    "                                   )\n",
    "\n",
    "    def execute(self, img, labels):\n",
    "        d_in = jt.contrib.concat((img.view((img.shape[0], (- 1))), self.label_embedding(labels)), dim=1)\n",
    "        # TODO(2): 将d_in输入到模型中并返回计算结果\n",
    "        # Your code starts here\n",
    "        validity = self.model(d_in)\n",
    "        return validity\n",
    "        # Your code ends here\n",
    "\n",
    "# 损失函数：平方误差\n",
    "# 调用方法：adversarial_loss(网络输出A, 分类标签B)\n",
    "# 计算结果：(A-B)^2\n",
    "adversarial_loss = nn.MSELoss()\n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2025-11-26 08:52:26--  https://cloud.tsinghua.edu.cn/f/b51b2b75cb03408e99be/?dl=1\n",
      "Resolving cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)... 101.6.15.69, 2402:f000:1:402:101:6:15:69\n",
      "Connecting to cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)|101.6.15.69|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cloud.tsinghua.edu.cn/seafhttp/files/715d20e7-5212-44c0-8fa2-351795114411/train-labels-idx1-ubyte.gz [following]\n",
      "--2025-11-26 08:52:26--  https://cloud.tsinghua.edu.cn/seafhttp/files/715d20e7-5212-44c0-8fa2-351795114411/train-labels-idx1-ubyte.gz\n",
      "Reusing existing connection to cloud.tsinghua.edu.cn:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 28881 (28K) [application/octet-stream]\n",
      "Saving to: ‘/root/.cache/jittor/dataset/mnist_data/train-labels-idx1-ubyte.gz’\n",
      "\n",
      "     0K .......... .......... ........                        100%  971K=0.03s\n",
      "\n",
      "2025-11-26 08:52:26 (971 KB/s) - ‘/root/.cache/jittor/dataset/mnist_data/train-labels-idx1-ubyte.gz’ saved [28881/28881]\n",
      "\n",
      "--2025-11-26 08:52:26--  https://cloud.tsinghua.edu.cn/f/6a88440968b84630bb71/?dl=1\n",
      "Resolving cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)... 101.6.15.69, 2402:f000:1:402:101:6:15:69\n",
      "Connecting to cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)|101.6.15.69|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cloud.tsinghua.edu.cn/seafhttp/files/9e3188e7-8f5f-4573-ac0c-798114c8d125/train-images-idx3-ubyte.gz [following]\n",
      "--2025-11-26 08:52:26--  https://cloud.tsinghua.edu.cn/seafhttp/files/9e3188e7-8f5f-4573-ac0c-798114c8d125/train-images-idx3-ubyte.gz\n",
      "Reusing existing connection to cloud.tsinghua.edu.cn:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9912422 (9.5M) [application/octet-stream]\n",
      "Saving to: ‘/root/.cache/jittor/dataset/mnist_data/train-images-idx3-ubyte.gz’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0%  501K 19s\n",
      "    50K .......... .......... .......... .......... ..........  1% 2.54M 11s\n",
      "   100K .......... .......... .......... .......... ..........  1% 3.35M 8s\n",
      "   150K .......... .......... .......... .......... ..........  2% 5.00M 7s\n",
      "   200K .......... .......... .......... .......... ..........  2% 4.95M 6s\n",
      "   250K .......... .......... .......... .......... ..........  3% 8.76M 5s\n",
      "   300K .......... .......... .......... .......... ..........  3% 10.9M 4s\n",
      "   350K .......... .......... .......... .......... ..........  4% 11.3M 4s\n",
      "   400K .......... .......... .......... .......... ..........  4% 13.5M 4s\n",
      "   450K .......... .......... .......... .......... ..........  5% 13.5M 3s\n",
      "   500K .......... .......... .......... .......... ..........  5% 11.8M 3s\n",
      "   550K .......... .......... .......... .......... ..........  6% 15.8M 3s\n",
      "   600K .......... .......... .......... .......... ..........  6% 19.1M 3s\n",
      "   650K .......... .......... .......... .......... ..........  7% 21.4M 2s\n",
      "   700K .......... .......... .......... .......... ..........  7% 24.3M 2s\n",
      "   750K .......... .......... .......... .......... ..........  8% 27.5M 2s\n",
      "   800K .......... .......... .......... .......... ..........  8% 19.2M 2s\n",
      "   850K .......... .......... .......... .......... ..........  9% 30.9M 2s\n",
      "   900K .......... .......... .......... .......... ..........  9% 20.5M 2s\n",
      "   950K .......... .......... .......... .......... .......... 10% 27.9M 2s\n",
      "  1000K .......... .......... .......... .......... .......... 10% 38.2M 2s\n",
      "  1050K .......... .......... .......... .......... .......... 11% 44.8M 2s\n",
      "  1100K .......... .......... .......... .......... .......... 11% 29.9M 2s\n",
      "  1150K .......... .......... .......... .......... .......... 12% 33.6M 1s\n",
      "  1200K .......... .......... .......... .......... .......... 12% 42.0M 1s\n",
      "  1250K .......... .......... .......... .......... .......... 13% 55.1M 1s\n",
      "  1300K .......... .......... .......... .......... .......... 13% 30.9M 1s\n",
      "  1350K .......... .......... .......... .......... .......... 14% 39.1M 1s\n",
      "  1400K .......... .......... .......... .......... .......... 14% 31.9M 1s\n",
      "  1450K .......... .......... .......... .......... .......... 15% 54.6M 1s\n",
      "  1500K .......... .......... .......... .......... .......... 16%  108M 1s\n",
      "  1550K .......... .......... .......... .......... .......... 16% 35.4M 1s\n",
      "  1600K .......... .......... .......... .......... .......... 17% 42.6M 1s\n",
      "  1650K .......... .......... .......... .......... .......... 17% 56.1M 1s\n",
      "  1700K .......... .......... .......... .......... .......... 18% 39.2M 1s\n",
      "  1750K .......... .......... .......... .......... .......... 18%  129M 1s\n",
      "  1800K .......... .......... .......... .......... .......... 19% 47.2M 1s\n",
      "  1850K .......... .......... .......... .......... .......... 19% 46.6M 1s\n",
      "  1900K .......... .......... .......... .......... .......... 20% 53.4M 1s\n",
      "  1950K .......... .......... .......... .......... .......... 20%  144M 1s\n",
      "  2000K .......... .......... .......... .......... .......... 21% 54.9M 1s\n",
      "  2050K .......... .......... .......... .......... .......... 21% 56.6M 1s\n",
      "  2100K .......... .......... .......... .......... .......... 22% 57.6M 1s\n",
      "  2150K .......... .......... .......... .......... .......... 22% 57.2M 1s\n",
      "  2200K .......... .......... .......... .......... .......... 23%  121M 1s\n",
      "  2250K .......... .......... .......... .......... .......... 23% 66.1M 1s\n",
      "  2300K .......... .......... .......... .......... .......... 24% 64.2M 1s\n",
      "  2350K .......... .......... .......... .......... .......... 24% 58.5M 1s\n",
      "  2400K .......... .......... .......... .......... .......... 25%  195M 1s\n",
      "  2450K .......... .......... .......... .......... .......... 25% 63.0M 1s\n",
      "  2500K .......... .......... .......... .......... .......... 26% 59.1M 1s\n",
      "  2550K .......... .......... .......... .......... .......... 26% 62.1M 1s\n",
      "  2600K .......... .......... .......... .......... .......... 27%  134M 1s\n",
      "  2650K .......... .......... .......... .......... .......... 27%  153M 1s\n",
      "  2700K .......... .......... .......... .......... .......... 28% 69.4M 1s\n",
      "  2750K .......... .......... .......... .......... .......... 28% 73.1M 1s\n",
      "  2800K .......... .......... .......... .......... .......... 29% 83.8M 1s\n",
      "  2850K .......... .......... .......... .......... .......... 29% 84.7M 1s\n",
      "  2900K .......... .......... .......... .......... .......... 30% 72.8M 1s\n",
      "  2950K .......... .......... .......... .......... .......... 30%  193M 1s\n",
      "  3000K .......... .......... .......... .......... .......... 31% 89.2M 1s\n",
      "  3050K .......... .......... .......... .......... .......... 32% 70.8M 0s\n",
      "  3100K .......... .......... .......... .......... .......... 32%  104M 0s\n",
      "  3150K .......... .......... .......... .......... .......... 33%  187M 0s\n",
      "  3200K .......... .......... .......... .......... .......... 33% 64.7M 0s\n",
      "  3250K .......... .......... .......... .......... .......... 34%  150M 0s\n",
      "  3300K .......... .......... .......... .......... .......... 34% 68.7M 0s\n",
      "  3350K .......... .......... .......... .......... .......... 35%  185M 0s\n",
      "  3400K .......... .......... .......... .......... .......... 35%  214M 0s\n",
      "  3450K .......... .......... .......... .......... .......... 36% 82.2M 0s\n",
      "  3500K .......... .......... .......... .......... .......... 36%  106M 0s\n",
      "  3550K .......... .......... .......... .......... .......... 37% 91.9M 0s\n",
      "  3600K .......... .......... .......... .......... .......... 37%  102M 0s\n",
      "  3650K .......... .......... .......... .......... .......... 38%  144M 0s\n",
      "  3700K .......... .......... .......... .......... .......... 38%  154M 0s\n",
      "  3750K .......... .......... .......... .......... .......... 39% 87.0M 0s\n",
      "  3800K .......... .......... .......... .......... .......... 39%  109M 0s\n",
      "  3850K .......... .......... .......... .......... .......... 40%  108M 0s\n",
      "  3900K .......... .......... .......... .......... .......... 40%  216M 0s\n",
      "  3950K .......... .......... .......... .......... .......... 41%  162M 0s\n",
      "  4000K .......... .......... .......... .......... .......... 41% 82.5M 0s\n",
      "  4050K .......... .......... .......... .......... .......... 42%  178M 0s\n",
      "  4100K .......... .......... .......... .......... .......... 42% 92.5M 0s\n",
      "  4150K .......... .......... .......... .......... .......... 43%  202M 0s\n",
      "  4200K .......... .......... .......... .......... .......... 43%  205M 0s\n",
      "  4250K .......... .......... .......... .......... .......... 44% 71.0M 0s\n",
      "  4300K .......... .......... .......... .......... .......... 44%  186M 0s\n",
      "  4350K .......... .......... .......... .......... .......... 45%  121M 0s\n",
      "  4400K .......... .......... .......... .......... .......... 45%  122M 0s\n",
      "  4450K .......... .......... .......... .......... .......... 46%  202M 0s\n",
      "  4500K .......... .......... .......... .......... .......... 47% 77.3M 0s\n",
      "  4550K .......... .......... .......... .......... .......... 47%  169M 0s\n",
      "  4600K .......... .......... .......... .......... .......... 48%  203M 0s\n",
      "  4650K .......... .......... .......... .......... .......... 48%  202M 0s\n",
      "  4700K .......... .......... .......... .......... .......... 49%  204M 0s\n",
      "  4750K .......... .......... .......... .......... .......... 49%  142M 0s\n",
      "  4800K .......... .......... .......... .......... .......... 50%  153M 0s\n",
      "  4850K .......... .......... .......... .......... .......... 50%  217M 0s\n",
      "  4900K .......... .......... .......... .......... .......... 51% 91.8M 0s\n",
      "  4950K .......... .......... .......... .......... .......... 51%  202M 0s\n",
      "  5000K .......... .......... .......... .......... .......... 52%  130M 0s\n",
      "  5050K .......... .......... .......... .......... .......... 52%  151M 0s\n",
      "  5100K .......... .......... .......... .......... .......... 53%  100M 0s\n",
      "  5150K .......... .......... .......... .......... .......... 53%  138M 0s\n",
      "  5200K .......... .......... .......... .......... .......... 54%  199M 0s\n",
      "  5250K .......... .......... .......... .......... .......... 54%  182M 0s\n",
      "  5300K .......... .......... .......... .......... .......... 55%  138M 0s\n",
      "  5350K .......... .......... .......... .......... .......... 55%  170M 0s\n",
      "  5400K .......... .......... .......... .......... .......... 56%  195M 0s\n",
      "  5450K .......... .......... .......... .......... .......... 56%  172M 0s\n",
      "  5500K .......... .......... .......... .......... .......... 57% 57.5M 0s\n",
      "  5550K .......... .......... .......... .......... .......... 57%  194M 0s\n",
      "  5600K .......... .......... .......... .......... .......... 58%  207M 0s\n",
      "  5650K .......... .......... .......... .......... .......... 58%  181M 0s\n",
      "  5700K .......... .......... .......... .......... .......... 59%  132M 0s\n",
      "  5750K .......... .......... .......... .......... .......... 59%  129M 0s\n",
      "  5800K .......... .......... .......... .......... .......... 60%  206M 0s\n",
      "  5850K .......... .......... .......... .......... .......... 60%  202M 0s\n",
      "  5900K .......... .......... .......... .......... .......... 61%  222M 0s\n",
      "  5950K .......... .......... .......... .......... .......... 61%  202M 0s\n",
      "  6000K .......... .......... .......... .......... .......... 62%  207M 0s\n",
      "  6050K .......... .......... .......... .......... .......... 63%  168M 0s\n",
      "  6100K .......... .......... .......... .......... .......... 63%  140M 0s\n",
      "  6150K .......... .......... .......... .......... .......... 64%  213M 0s\n",
      "  6200K .......... .......... .......... .......... .......... 64% 62.5M 0s\n",
      "  6250K .......... .......... .......... .......... .......... 65%  164M 0s\n",
      "  6300K .......... .......... .......... .......... .......... 65%  118M 0s\n",
      "  6350K .......... .......... .......... .......... .......... 66%  152M 0s\n",
      "  6400K .......... .......... .......... .......... .......... 66%  104M 0s\n",
      "  6450K .......... .......... .......... .......... .......... 67%  131M 0s\n",
      "  6500K .......... .......... .......... .......... .......... 67%  108M 0s\n",
      "  6550K .......... .......... .......... .......... .......... 68%  117M 0s\n",
      "  6600K .......... .......... .......... .......... .......... 68%  122M 0s\n",
      "  6650K .......... .......... .......... .......... .......... 69%  117M 0s\n",
      "  6700K .......... .......... .......... .......... .......... 69%  126M 0s\n",
      "  6750K .......... .......... .......... .......... .......... 70%  115M 0s\n",
      "  6800K .......... .......... .......... .......... .......... 70% 76.5M 0s\n",
      "  6850K .......... .......... .......... .......... .......... 71%  146M 0s\n",
      "  6900K .......... .......... .......... .......... .......... 71%  136M 0s\n",
      "  6950K .......... .......... .......... .......... .......... 72% 13.1M 0s\n",
      "  7000K .......... .......... .......... .......... .......... 72%  101M 0s\n",
      "  7050K .......... .......... .......... .......... .......... 73%  114M 0s\n",
      "  7100K .......... .......... .......... .......... .......... 73%  147M 0s\n",
      "  7150K .......... .......... .......... .......... .......... 74%  122M 0s\n",
      "  7200K .......... .......... .......... .......... .......... 74%  144M 0s\n",
      "  7250K .......... .......... .......... .......... .......... 75%  147M 0s\n",
      "  7300K .......... .......... .......... .......... .......... 75%  140M 0s\n",
      "  7350K .......... .......... .......... .......... .......... 76%  189M 0s\n",
      "  7400K .......... .......... .......... .......... .......... 76%  155M 0s\n",
      "  7450K .......... .......... .......... .......... .......... 77%  129M 0s\n",
      "  7500K .......... .......... .......... .......... .......... 77%  181M 0s\n",
      "  7550K .......... .......... .......... .......... .......... 78%  204M 0s\n",
      "  7600K .......... .......... .......... .......... .......... 79%  201M 0s\n",
      "  7650K .......... .......... .......... .......... .......... 79%  218M 0s\n",
      "  7700K .......... .......... .......... .......... .......... 80%  166M 0s\n",
      "  7750K .......... .......... .......... .......... .......... 80%  218M 0s\n",
      "  7800K .......... .......... .......... .......... .......... 81%  204M 0s\n",
      "  7850K .......... .......... .......... .......... .......... 81%  195M 0s\n",
      "  7900K .......... .......... .......... .......... .......... 82%  218M 0s\n",
      "  7950K .......... .......... .......... .......... .......... 82%  219M 0s\n",
      "  8000K .......... .......... .......... .......... .......... 83%  209M 0s\n",
      "  8050K .......... .......... .......... .......... .......... 83%  203M 0s\n",
      "  8100K .......... .......... .......... .......... .......... 84%  168M 0s\n",
      "  8150K .......... .......... .......... .......... .......... 84%  220M 0s\n",
      "  8200K .......... .......... .......... .......... .......... 85%  216M 0s\n",
      "  8250K .......... .......... .......... .......... .......... 85%  213M 0s\n",
      "  8300K .......... .......... .......... .......... .......... 86%  220M 0s\n",
      "  8350K .......... .......... .......... .......... .......... 86%  220M 0s\n",
      "  8400K .......... .......... .......... .......... .......... 87% 39.5M 0s\n",
      "  8450K .......... .......... .......... .......... .......... 87%  200M 0s\n",
      "  8500K .......... .......... .......... .......... .......... 88%  145M 0s\n",
      "  8550K .......... .......... .......... .......... .......... 88%  188M 0s\n",
      "  8600K .......... .......... .......... .......... .......... 89%  193M 0s\n",
      "  8650K .......... .......... .......... .......... .......... 89%  203M 0s\n",
      "  8700K .......... .......... .......... .......... .......... 90%  220M 0s\n",
      "  8750K .......... .......... .......... .......... .......... 90%  206M 0s\n",
      "  8800K .......... .......... .......... .......... .......... 91%  205M 0s\n",
      "  8850K .......... .......... .......... .......... .......... 91%  222M 0s\n",
      "  8900K .......... .......... .......... .......... .......... 92%  151M 0s\n",
      "  8950K .......... .......... .......... .......... .......... 92%  221M 0s\n",
      "  9000K .......... .......... .......... .......... .......... 93%  218M 0s\n",
      "  9050K .......... .......... .......... .......... .......... 94%  220M 0s\n",
      "  9100K .......... .......... .......... .......... .......... 94%  225M 0s\n",
      "  9150K .......... .......... .......... .......... .......... 95%  197M 0s\n",
      "  9200K .......... .......... .......... .......... .......... 95%  192M 0s\n",
      "  9250K .......... .......... .......... .......... .......... 96%  219M 0s\n",
      "  9300K .......... .......... .......... .......... .......... 96%  167M 0s\n",
      "  9350K .......... .......... .......... .......... .......... 97%  205M 0s\n",
      "  9400K .......... .......... .......... .......... .......... 97%  219M 0s\n",
      "  9450K .......... .......... .......... .......... .......... 98%  224M 0s\n",
      "  9500K .......... .......... .......... .......... .......... 98%  203M 0s\n",
      "  9550K .......... .......... .......... .......... .......... 99%  126M 0s\n",
      "  9600K .......... .......... .......... .......... .......... 99%  109M 0s\n",
      "  9650K .......... .......... ..........                      100%  176M=0.3s\n",
      "\n",
      "2025-11-26 08:52:27 (33.4 MB/s) - ‘/root/.cache/jittor/dataset/mnist_data/train-images-idx3-ubyte.gz’ saved [9912422/9912422]\n",
      "\n",
      "--2025-11-26 08:52:27--  https://cloud.tsinghua.edu.cn/f/f17348dfafbd420d8dee/?dl=1\n",
      "Resolving cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)... 101.6.15.69, 2402:f000:1:402:101:6:15:69\n",
      "Connecting to cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)|101.6.15.69|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cloud.tsinghua.edu.cn/seafhttp/files/59d5ba78-9282-466d-8f1e-b791cb8be058/t10k-images-idx3-ubyte.gz [following]\n",
      "--2025-11-26 08:52:27--  https://cloud.tsinghua.edu.cn/seafhttp/files/59d5ba78-9282-466d-8f1e-b791cb8be058/t10k-images-idx3-ubyte.gz\n",
      "Reusing existing connection to cloud.tsinghua.edu.cn:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1648877 (1.6M) [application/octet-stream]\n",
      "Saving to: ‘/root/.cache/jittor/dataset/mnist_data/t10k-images-idx3-ubyte.gz’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  3%  898K 2s\n",
      "    50K .......... .......... .......... .......... ..........  6% 2.97M 1s\n",
      "   100K .......... .......... .......... .......... ..........  9% 4.11M 1s\n",
      "   150K .......... .......... .......... .......... .......... 12% 4.23M 1s\n",
      "   200K .......... .......... .......... .......... .......... 15% 6.96M 1s\n",
      "   250K .......... .......... .......... .......... .......... 18% 10.2M 0s\n",
      "   300K .......... .......... .......... .......... .......... 21% 9.42M 0s\n",
      "   350K .......... .......... .......... .......... .......... 24% 14.0M 0s\n",
      "   400K .......... .......... .......... .......... .......... 27% 11.6M 0s\n",
      "   450K .......... .......... .......... .......... .......... 31% 14.7M 0s\n",
      "   500K .......... .......... .......... .......... .......... 34% 21.0M 0s\n",
      "   550K .......... .......... .......... .......... .......... 37% 13.3M 0s\n",
      "   600K .......... .......... .......... .......... .......... 40% 21.4M 0s\n",
      "   650K .......... .......... .......... .......... .......... 43% 17.7M 0s\n",
      "   700K .......... .......... .......... .......... .......... 46% 23.8M 0s\n",
      "   750K .......... .......... .......... .......... .......... 49% 27.4M 0s\n",
      "   800K .......... .......... .......... .......... .......... 52% 29.7M 0s\n",
      "   850K .......... .......... .......... .......... .......... 55% 22.3M 0s\n",
      "   900K .......... .......... .......... .......... .......... 58% 46.9M 0s\n",
      "   950K .......... .......... .......... .......... .......... 62% 21.2M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 65% 26.7M 0s\n",
      "  1050K .......... .......... .......... .......... .......... 68% 46.9M 0s\n",
      "  1100K .......... .......... .......... .......... .......... 71% 33.1M 0s\n",
      "  1150K .......... .......... .......... .......... .......... 74% 42.4M 0s\n",
      "  1200K .......... .......... .......... .......... .......... 77% 30.6M 0s\n",
      "  1250K .......... .......... .......... .......... .......... 80% 59.3M 0s\n",
      "  1300K .......... .......... .......... .......... .......... 83% 35.3M 0s\n",
      "  1350K .......... .......... .......... .......... .......... 86% 34.0M 0s\n",
      "  1400K .......... .......... .......... .......... .......... 90% 49.7M 0s\n",
      "  1450K .......... .......... .......... .......... .......... 93% 85.6M 0s\n",
      "  1500K .......... .......... .......... .......... .......... 96% 41.9M 0s\n",
      "  1550K .......... .......... .......... .......... .......... 99% 37.1M 0s\n",
      "  1600K ..........                                            100%  133M=0.2s\n",
      "\n",
      "2025-11-26 08:52:27 (9.80 MB/s) - ‘/root/.cache/jittor/dataset/mnist_data/t10k-images-idx3-ubyte.gz’ saved [1648877/1648877]\n",
      "\n",
      "--2025-11-26 08:52:27--  https://cloud.tsinghua.edu.cn/f/3b34d4ad70db4c34bb4c/?dl=1\n",
      "Resolving cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)... 101.6.15.69, 2402:f000:1:402:101:6:15:69\n",
      "Connecting to cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)|101.6.15.69|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cloud.tsinghua.edu.cn/seafhttp/files/b3408967-0f3b-45bc-bda8-e979b8dfeb54/t10k-labels-idx1-ubyte.gz [following]\n",
      "--2025-11-26 08:52:27--  https://cloud.tsinghua.edu.cn/seafhttp/files/b3408967-0f3b-45bc-bda8-e979b8dfeb54/t10k-labels-idx1-ubyte.gz\n",
      "Reusing existing connection to cloud.tsinghua.edu.cn:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4542 (4.4K) [application/octet-stream]\n",
      "Saving to: ‘/root/.cache/jittor/dataset/mnist_data/t10k-labels-idx1-ubyte.gz’\n",
      "\n",
      "     0K ....                                                  100%  800K=0.006s\n",
      "\n",
      "2025-11-26 08:52:27 (800 KB/s) - ‘/root/.cache/jittor/dataset/mnist_data/t10k-labels-idx1-ubyte.gz’ saved [4542/4542]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.system(\"mkdir -p ~/.cache/jittor/dataset/mnist_data\")\n",
    "os.system(\"wget -O ~/.cache/jittor/dataset/mnist_data/train-labels-idx1-ubyte.gz 'https://cloud.tsinghua.edu.cn/f/b51b2b75cb03408e99be/?dl=1'\")\n",
    "os.system(\"wget -O ~/.cache/jittor/dataset/mnist_data/train-images-idx3-ubyte.gz 'https://cloud.tsinghua.edu.cn/f/6a88440968b84630bb71/?dl=1'\")\n",
    "os.system(\"wget -O ~/.cache/jittor/dataset/mnist_data/t10k-images-idx3-ubyte.gz 'https://cloud.tsinghua.edu.cn/f/f17348dfafbd420d8dee/?dl=1'\")\n",
    "os.system(\"wget -O ~/.cache/jittor/dataset/mnist_data/t10k-labels-idx1-ubyte.gz 'https://cloud.tsinghua.edu.cn/f/3b34d4ad70db4c34bb4c/?dl=1'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入MNIST数据集\n",
    "from jittor.dataset.mnist import MNIST\n",
    "import jittor.transform as transform\n",
    "transform = transform.Compose([\n",
    "    transform.Resize(img_size),\n",
    "    transform.Gray(),\n",
    "    transform.ImageNormalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "dataloader = MNIST(download=False, train=True, transform=transform).set_attrs(batch_size=batch_size, shuffle=True)\n",
    "\n",
    "optimizer_G = nn.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = nn.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def save_image(img, path, nrow=10, padding=5):\n",
    "    N,C,W,H = img.shape\n",
    "    if (N%nrow!=0):\n",
    "        print(\"N%nrow!=0\")\n",
    "        return\n",
    "    ncol=int(N/nrow)\n",
    "    img_all = []\n",
    "    for i in range(ncol):\n",
    "        img_ = []\n",
    "        for j in range(nrow):\n",
    "            img_.append(img[i*nrow+j])\n",
    "            img_.append(np.zeros((C,W,padding)))\n",
    "        img_all.append(np.concatenate(img_, 2))\n",
    "        img_all.append(np.zeros((C,padding,img_all[0].shape[2])))\n",
    "    img = np.concatenate(img_all, 1)\n",
    "    img = np.concatenate([np.zeros((C,padding,img.shape[2])), img], 1)\n",
    "    img = np.concatenate([np.zeros((C,img.shape[1],padding)), img], 2)\n",
    "    min_=img.min()\n",
    "    max_=img.max()\n",
    "    img=(img-min_)/(max_-min_)*255\n",
    "    img=img.transpose((1,2,0))\n",
    "    if C==3:\n",
    "        img = img[:,:,::-1]\n",
    "    elif C==1:\n",
    "        img = img[:,:,0]\n",
    "    Image.fromarray(np.uint8(img)).save(path)\n",
    "\n",
    "def sample_image(n_row, batches_done):\n",
    "    # 随机采样输入并保存生成的图片\n",
    "    z = jt.array(np.random.normal(0, 1, (n_row ** 2, latent_dim))).float32().stop_grad()\n",
    "    labels = jt.array(np.array([num for _ in range(n_row) for num in range(n_row)])).float32().stop_grad()\n",
    "    gen_imgs = generator(z, labels)\n",
    "    save_image(gen_imgs.numpy(), \"%d.png\" % batches_done, nrow=n_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/10] [Batch 0/3750] [D loss: 0.224154] [G loss: 0.370331]\n",
      "[Epoch 0/10] [Batch 50/3750] [D loss: 0.195470] [G loss: 0.420044]\n",
      "[Epoch 0/10] [Batch 100/3750] [D loss: 0.231061] [G loss: 0.319449]\n",
      "[Epoch 0/10] [Batch 150/3750] [D loss: 0.231848] [G loss: 0.415048]\n",
      "[Epoch 0/10] [Batch 200/3750] [D loss: 0.217403] [G loss: 0.413310]\n",
      "[Epoch 0/10] [Batch 250/3750] [D loss: 0.201741] [G loss: 0.359974]\n",
      "[Epoch 0/10] [Batch 300/3750] [D loss: 0.212848] [G loss: 0.333282]\n",
      "[Epoch 0/10] [Batch 350/3750] [D loss: 0.222336] [G loss: 0.377559]\n",
      "[Epoch 0/10] [Batch 400/3750] [D loss: 0.242510] [G loss: 0.352097]\n",
      "[Epoch 0/10] [Batch 450/3750] [D loss: 0.209855] [G loss: 0.414091]\n",
      "[Epoch 0/10] [Batch 500/3750] [D loss: 0.204169] [G loss: 0.435830]\n",
      "[Epoch 0/10] [Batch 550/3750] [D loss: 0.207255] [G loss: 0.401550]\n",
      "[Epoch 0/10] [Batch 600/3750] [D loss: 0.272008] [G loss: 0.293793]\n",
      "[Epoch 0/10] [Batch 650/3750] [D loss: 0.233672] [G loss: 0.306144]\n",
      "[Epoch 0/10] [Batch 700/3750] [D loss: 0.220501] [G loss: 0.405061]\n",
      "[Epoch 0/10] [Batch 750/3750] [D loss: 0.215196] [G loss: 0.353404]\n",
      "[Epoch 0/10] [Batch 800/3750] [D loss: 0.191880] [G loss: 0.368183]\n",
      "[Epoch 0/10] [Batch 850/3750] [D loss: 0.220746] [G loss: 0.421745]\n",
      "[Epoch 0/10] [Batch 900/3750] [D loss: 0.192651] [G loss: 0.382712]\n",
      "[Epoch 0/10] [Batch 950/3750] [D loss: 0.244939] [G loss: 0.331957]\n",
      "[Epoch 0/10] [Batch 1000/3750] [D loss: 0.210662] [G loss: 0.326539]\n",
      "[Epoch 0/10] [Batch 1050/3750] [D loss: 0.245000] [G loss: 0.338329]\n",
      "[Epoch 0/10] [Batch 1100/3750] [D loss: 0.207939] [G loss: 0.385434]\n",
      "[Epoch 0/10] [Batch 1150/3750] [D loss: 0.225814] [G loss: 0.311355]\n",
      "[Epoch 0/10] [Batch 1200/3750] [D loss: 0.212846] [G loss: 0.372898]\n",
      "[Epoch 0/10] [Batch 1250/3750] [D loss: 0.228901] [G loss: 0.382789]\n",
      "[Epoch 0/10] [Batch 1300/3750] [D loss: 0.238718] [G loss: 0.374656]\n",
      "[Epoch 0/10] [Batch 1350/3750] [D loss: 0.261380] [G loss: 0.328118]\n",
      "[Epoch 0/10] [Batch 1400/3750] [D loss: 0.218901] [G loss: 0.377994]\n",
      "[Epoch 0/10] [Batch 1450/3750] [D loss: 0.253448] [G loss: 0.318957]\n",
      "[Epoch 0/10] [Batch 1500/3750] [D loss: 0.252465] [G loss: 0.377435]\n",
      "[Epoch 0/10] [Batch 1550/3750] [D loss: 0.202410] [G loss: 0.449150]\n",
      "[Epoch 0/10] [Batch 1600/3750] [D loss: 0.213347] [G loss: 0.334319]\n",
      "[Epoch 0/10] [Batch 1650/3750] [D loss: 0.218644] [G loss: 0.365532]\n",
      "[Epoch 0/10] [Batch 1700/3750] [D loss: 0.264751] [G loss: 0.291100]\n",
      "[Epoch 0/10] [Batch 1750/3750] [D loss: 0.236866] [G loss: 0.359252]\n",
      "[Epoch 0/10] [Batch 1800/3750] [D loss: 0.217248] [G loss: 0.354615]\n",
      "[Epoch 0/10] [Batch 1850/3750] [D loss: 0.203432] [G loss: 0.365067]\n",
      "[Epoch 0/10] [Batch 1900/3750] [D loss: 0.188754] [G loss: 0.395187]\n",
      "[Epoch 0/10] [Batch 1950/3750] [D loss: 0.242326] [G loss: 0.329440]\n",
      "[Epoch 0/10] [Batch 2000/3750] [D loss: 0.253498] [G loss: 0.348827]\n",
      "[Epoch 0/10] [Batch 2050/3750] [D loss: 0.174721] [G loss: 0.355143]\n",
      "[Epoch 0/10] [Batch 2100/3750] [D loss: 0.187428] [G loss: 0.398061]\n",
      "[Epoch 0/10] [Batch 2150/3750] [D loss: 0.177281] [G loss: 0.423420]\n",
      "[Epoch 0/10] [Batch 2200/3750] [D loss: 0.226762] [G loss: 0.367091]\n",
      "[Epoch 0/10] [Batch 2250/3750] [D loss: 0.202024] [G loss: 0.357711]\n",
      "[Epoch 0/10] [Batch 2300/3750] [D loss: 0.214883] [G loss: 0.344615]\n",
      "[Epoch 0/10] [Batch 2350/3750] [D loss: 0.221187] [G loss: 0.313902]\n",
      "[Epoch 0/10] [Batch 2400/3750] [D loss: 0.250379] [G loss: 0.306732]\n",
      "[Epoch 0/10] [Batch 2450/3750] [D loss: 0.220519] [G loss: 0.349282]\n",
      "[Epoch 0/10] [Batch 2500/3750] [D loss: 0.207354] [G loss: 0.364642]\n",
      "[Epoch 0/10] [Batch 2550/3750] [D loss: 0.216558] [G loss: 0.372209]\n",
      "[Epoch 0/10] [Batch 2600/3750] [D loss: 0.225949] [G loss: 0.341294]\n",
      "[Epoch 0/10] [Batch 2650/3750] [D loss: 0.238742] [G loss: 0.316463]\n",
      "[Epoch 0/10] [Batch 2700/3750] [D loss: 0.211036] [G loss: 0.342762]\n",
      "[Epoch 0/10] [Batch 2750/3750] [D loss: 0.213310] [G loss: 0.356426]\n",
      "[Epoch 0/10] [Batch 2800/3750] [D loss: 0.213817] [G loss: 0.448301]\n",
      "[Epoch 0/10] [Batch 2850/3750] [D loss: 0.204691] [G loss: 0.375696]\n",
      "[Epoch 0/10] [Batch 2900/3750] [D loss: 0.236996] [G loss: 0.372466]\n",
      "[Epoch 0/10] [Batch 2950/3750] [D loss: 0.262185] [G loss: 0.328598]\n",
      "[Epoch 0/10] [Batch 3000/3750] [D loss: 0.237599] [G loss: 0.320124]\n",
      "[Epoch 0/10] [Batch 3050/3750] [D loss: 0.196712] [G loss: 0.451973]\n",
      "[Epoch 0/10] [Batch 3100/3750] [D loss: 0.254516] [G loss: 0.341593]\n",
      "[Epoch 0/10] [Batch 3150/3750] [D loss: 0.211625] [G loss: 0.398901]\n",
      "[Epoch 0/10] [Batch 3200/3750] [D loss: 0.234883] [G loss: 0.340561]\n",
      "[Epoch 0/10] [Batch 3250/3750] [D loss: 0.184910] [G loss: 0.396076]\n",
      "[Epoch 0/10] [Batch 3300/3750] [D loss: 0.235222] [G loss: 0.374084]\n",
      "[Epoch 0/10] [Batch 3350/3750] [D loss: 0.230726] [G loss: 0.380023]\n",
      "[Epoch 0/10] [Batch 3400/3750] [D loss: 0.236209] [G loss: 0.379488]\n",
      "[Epoch 0/10] [Batch 3450/3750] [D loss: 0.260102] [G loss: 0.302207]\n",
      "[Epoch 0/10] [Batch 3500/3750] [D loss: 0.200669] [G loss: 0.341963]\n",
      "[Epoch 0/10] [Batch 3550/3750] [D loss: 0.236493] [G loss: 0.297440]\n",
      "[Epoch 0/10] [Batch 3600/3750] [D loss: 0.194544] [G loss: 0.391373]\n",
      "[Epoch 0/10] [Batch 3650/3750] [D loss: 0.199927] [G loss: 0.366505]\n",
      "[Epoch 0/10] [Batch 3700/3750] [D loss: 0.213890] [G loss: 0.372554]\n",
      "[Epoch 1/10] [Batch 0/3750] [D loss: 0.227502] [G loss: 0.391053]\n",
      "[Epoch 1/10] [Batch 50/3750] [D loss: 0.202575] [G loss: 0.363584]\n",
      "[Epoch 1/10] [Batch 100/3750] [D loss: 0.204791] [G loss: 0.350129]\n",
      "[Epoch 1/10] [Batch 150/3750] [D loss: 0.248198] [G loss: 0.413223]\n",
      "[Epoch 1/10] [Batch 200/3750] [D loss: 0.190167] [G loss: 0.391553]\n",
      "[Epoch 1/10] [Batch 250/3750] [D loss: 0.210380] [G loss: 0.364229]\n",
      "[Epoch 1/10] [Batch 300/3750] [D loss: 0.216842] [G loss: 0.367287]\n",
      "[Epoch 1/10] [Batch 350/3750] [D loss: 0.211607] [G loss: 0.361366]\n",
      "[Epoch 1/10] [Batch 400/3750] [D loss: 0.211437] [G loss: 0.409310]\n",
      "[Epoch 1/10] [Batch 450/3750] [D loss: 0.273118] [G loss: 0.274470]\n",
      "[Epoch 1/10] [Batch 500/3750] [D loss: 0.235061] [G loss: 0.347648]\n",
      "[Epoch 1/10] [Batch 550/3750] [D loss: 0.213266] [G loss: 0.410403]\n",
      "[Epoch 1/10] [Batch 600/3750] [D loss: 0.179846] [G loss: 0.384670]\n",
      "[Epoch 1/10] [Batch 650/3750] [D loss: 0.227963] [G loss: 0.460236]\n",
      "[Epoch 1/10] [Batch 700/3750] [D loss: 0.225424] [G loss: 0.349648]\n",
      "[Epoch 1/10] [Batch 750/3750] [D loss: 0.246739] [G loss: 0.376115]\n",
      "[Epoch 1/10] [Batch 800/3750] [D loss: 0.234184] [G loss: 0.373415]\n",
      "[Epoch 1/10] [Batch 850/3750] [D loss: 0.238046] [G loss: 0.328484]\n",
      "[Epoch 1/10] [Batch 900/3750] [D loss: 0.208317] [G loss: 0.398060]\n",
      "[Epoch 1/10] [Batch 950/3750] [D loss: 0.238171] [G loss: 0.361343]\n",
      "[Epoch 1/10] [Batch 1000/3750] [D loss: 0.233644] [G loss: 0.364768]\n",
      "[Epoch 1/10] [Batch 1050/3750] [D loss: 0.249338] [G loss: 0.349570]\n",
      "[Epoch 1/10] [Batch 1100/3750] [D loss: 0.228329] [G loss: 0.404256]\n",
      "[Epoch 1/10] [Batch 1150/3750] [D loss: 0.214385] [G loss: 0.331197]\n",
      "[Epoch 1/10] [Batch 1200/3750] [D loss: 0.282692] [G loss: 0.299057]\n",
      "[Epoch 1/10] [Batch 1250/3750] [D loss: 0.174736] [G loss: 0.414300]\n",
      "[Epoch 1/10] [Batch 1300/3750] [D loss: 0.244689] [G loss: 0.358014]\n",
      "[Epoch 1/10] [Batch 1350/3750] [D loss: 0.205831] [G loss: 0.367403]\n",
      "[Epoch 1/10] [Batch 1400/3750] [D loss: 0.238123] [G loss: 0.328475]\n",
      "[Epoch 1/10] [Batch 1450/3750] [D loss: 0.190006] [G loss: 0.374071]\n",
      "[Epoch 1/10] [Batch 1500/3750] [D loss: 0.204431] [G loss: 0.354316]\n",
      "[Epoch 1/10] [Batch 1550/3750] [D loss: 0.210378] [G loss: 0.355314]\n",
      "[Epoch 1/10] [Batch 1600/3750] [D loss: 0.212096] [G loss: 0.356520]\n",
      "[Epoch 1/10] [Batch 1650/3750] [D loss: 0.212674] [G loss: 0.341711]\n",
      "[Epoch 1/10] [Batch 1700/3750] [D loss: 0.239587] [G loss: 0.335777]\n",
      "[Epoch 1/10] [Batch 1750/3750] [D loss: 0.237691] [G loss: 0.280555]\n",
      "[Epoch 1/10] [Batch 1800/3750] [D loss: 0.200395] [G loss: 0.361379]\n",
      "[Epoch 1/10] [Batch 1850/3750] [D loss: 0.261196] [G loss: 0.347961]\n",
      "[Epoch 1/10] [Batch 1900/3750] [D loss: 0.201844] [G loss: 0.384623]\n",
      "[Epoch 1/10] [Batch 1950/3750] [D loss: 0.186782] [G loss: 0.425415]\n",
      "[Epoch 1/10] [Batch 2000/3750] [D loss: 0.238525] [G loss: 0.304174]\n",
      "[Epoch 1/10] [Batch 2050/3750] [D loss: 0.238530] [G loss: 0.411095]\n",
      "[Epoch 1/10] [Batch 2100/3750] [D loss: 0.226457] [G loss: 0.356281]\n",
      "[Epoch 1/10] [Batch 2150/3750] [D loss: 0.223809] [G loss: 0.362751]\n",
      "[Epoch 1/10] [Batch 2200/3750] [D loss: 0.250800] [G loss: 0.296957]\n",
      "[Epoch 1/10] [Batch 2250/3750] [D loss: 0.224277] [G loss: 0.352444]\n",
      "[Epoch 1/10] [Batch 2300/3750] [D loss: 0.184860] [G loss: 0.475238]\n",
      "[Epoch 1/10] [Batch 2350/3750] [D loss: 0.201392] [G loss: 0.365219]\n",
      "[Epoch 1/10] [Batch 2400/3750] [D loss: 0.223901] [G loss: 0.376869]\n",
      "[Epoch 1/10] [Batch 2450/3750] [D loss: 0.199591] [G loss: 0.437570]\n",
      "[Epoch 1/10] [Batch 2500/3750] [D loss: 0.227969] [G loss: 0.376498]\n",
      "[Epoch 1/10] [Batch 2550/3750] [D loss: 0.219195] [G loss: 0.360184]\n",
      "[Epoch 1/10] [Batch 2600/3750] [D loss: 0.168050] [G loss: 0.403923]\n",
      "[Epoch 1/10] [Batch 2650/3750] [D loss: 0.189609] [G loss: 0.411611]\n",
      "[Epoch 1/10] [Batch 2700/3750] [D loss: 0.221269] [G loss: 0.424003]\n",
      "[Epoch 1/10] [Batch 2750/3750] [D loss: 0.244290] [G loss: 0.350361]\n",
      "[Epoch 1/10] [Batch 2800/3750] [D loss: 0.225288] [G loss: 0.388563]\n",
      "[Epoch 1/10] [Batch 2850/3750] [D loss: 0.208078] [G loss: 0.414948]\n",
      "[Epoch 1/10] [Batch 2900/3750] [D loss: 0.213596] [G loss: 0.396502]\n",
      "[Epoch 1/10] [Batch 2950/3750] [D loss: 0.243399] [G loss: 0.378145]\n",
      "[Epoch 1/10] [Batch 3000/3750] [D loss: 0.201035] [G loss: 0.427978]\n",
      "[Epoch 1/10] [Batch 3050/3750] [D loss: 0.211855] [G loss: 0.359703]\n",
      "[Epoch 1/10] [Batch 3100/3750] [D loss: 0.199315] [G loss: 0.364737]\n",
      "[Epoch 1/10] [Batch 3150/3750] [D loss: 0.281693] [G loss: 0.294547]\n",
      "[Epoch 1/10] [Batch 3200/3750] [D loss: 0.230224] [G loss: 0.375087]\n",
      "[Epoch 1/10] [Batch 3250/3750] [D loss: 0.236595] [G loss: 0.297997]\n",
      "[Epoch 1/10] [Batch 3300/3750] [D loss: 0.253227] [G loss: 0.380027]\n",
      "[Epoch 1/10] [Batch 3350/3750] [D loss: 0.216459] [G loss: 0.340223]\n",
      "[Epoch 1/10] [Batch 3400/3750] [D loss: 0.217114] [G loss: 0.387835]\n",
      "[Epoch 1/10] [Batch 3450/3750] [D loss: 0.221228] [G loss: 0.360554]\n",
      "[Epoch 1/10] [Batch 3500/3750] [D loss: 0.193633] [G loss: 0.406303]\n",
      "[Epoch 1/10] [Batch 3550/3750] [D loss: 0.219349] [G loss: 0.369369]\n",
      "[Epoch 1/10] [Batch 3600/3750] [D loss: 0.230981] [G loss: 0.336295]\n",
      "[Epoch 1/10] [Batch 3650/3750] [D loss: 0.229552] [G loss: 0.381826]\n",
      "[Epoch 1/10] [Batch 3700/3750] [D loss: 0.214253] [G loss: 0.425638]\n",
      "[Epoch 2/10] [Batch 0/3750] [D loss: 0.206581] [G loss: 0.399758]\n",
      "[Epoch 2/10] [Batch 50/3750] [D loss: 0.228206] [G loss: 0.368694]\n",
      "[Epoch 2/10] [Batch 100/3750] [D loss: 0.213927] [G loss: 0.345785]\n",
      "[Epoch 2/10] [Batch 150/3750] [D loss: 0.189791] [G loss: 0.400975]\n",
      "[Epoch 2/10] [Batch 200/3750] [D loss: 0.231109] [G loss: 0.356760]\n",
      "[Epoch 2/10] [Batch 250/3750] [D loss: 0.218591] [G loss: 0.332269]\n",
      "[Epoch 2/10] [Batch 300/3750] [D loss: 0.276612] [G loss: 0.260814]\n",
      "[Epoch 2/10] [Batch 350/3750] [D loss: 0.244481] [G loss: 0.369471]\n",
      "[Epoch 2/10] [Batch 400/3750] [D loss: 0.249256] [G loss: 0.349437]\n",
      "[Epoch 2/10] [Batch 450/3750] [D loss: 0.229645] [G loss: 0.413926]\n",
      "[Epoch 2/10] [Batch 500/3750] [D loss: 0.220915] [G loss: 0.415624]\n",
      "[Epoch 2/10] [Batch 550/3750] [D loss: 0.236051] [G loss: 0.330432]\n",
      "[Epoch 2/10] [Batch 600/3750] [D loss: 0.263249] [G loss: 0.353616]\n",
      "[Epoch 2/10] [Batch 650/3750] [D loss: 0.190838] [G loss: 0.349310]\n",
      "[Epoch 2/10] [Batch 700/3750] [D loss: 0.211376] [G loss: 0.394461]\n",
      "[Epoch 2/10] [Batch 750/3750] [D loss: 0.211490] [G loss: 0.418468]\n",
      "[Epoch 2/10] [Batch 800/3750] [D loss: 0.199108] [G loss: 0.366532]\n",
      "[Epoch 2/10] [Batch 850/3750] [D loss: 0.230460] [G loss: 0.353910]\n",
      "[Epoch 2/10] [Batch 900/3750] [D loss: 0.232103] [G loss: 0.312144]\n",
      "[Epoch 2/10] [Batch 950/3750] [D loss: 0.197686] [G loss: 0.377752]\n",
      "[Epoch 2/10] [Batch 1000/3750] [D loss: 0.229275] [G loss: 0.338057]\n",
      "[Epoch 2/10] [Batch 1050/3750] [D loss: 0.215932] [G loss: 0.397537]\n",
      "[Epoch 2/10] [Batch 1100/3750] [D loss: 0.253664] [G loss: 0.376002]\n",
      "[Epoch 2/10] [Batch 1150/3750] [D loss: 0.189760] [G loss: 0.390456]\n",
      "[Epoch 2/10] [Batch 1200/3750] [D loss: 0.221929] [G loss: 0.346464]\n",
      "[Epoch 2/10] [Batch 1250/3750] [D loss: 0.201317] [G loss: 0.452977]\n",
      "[Epoch 2/10] [Batch 1300/3750] [D loss: 0.225946] [G loss: 0.352478]\n",
      "[Epoch 2/10] [Batch 1350/3750] [D loss: 0.258310] [G loss: 0.322728]\n",
      "[Epoch 2/10] [Batch 1400/3750] [D loss: 0.219274] [G loss: 0.311560]\n",
      "[Epoch 2/10] [Batch 1450/3750] [D loss: 0.245063] [G loss: 0.356709]\n",
      "[Epoch 2/10] [Batch 1500/3750] [D loss: 0.237093] [G loss: 0.319717]\n",
      "[Epoch 2/10] [Batch 1550/3750] [D loss: 0.229597] [G loss: 0.349389]\n",
      "[Epoch 2/10] [Batch 1600/3750] [D loss: 0.206244] [G loss: 0.358202]\n",
      "[Epoch 2/10] [Batch 1650/3750] [D loss: 0.262114] [G loss: 0.335216]\n",
      "[Epoch 2/10] [Batch 1700/3750] [D loss: 0.206336] [G loss: 0.365751]\n",
      "[Epoch 2/10] [Batch 1750/3750] [D loss: 0.195808] [G loss: 0.294903]\n",
      "[Epoch 2/10] [Batch 1800/3750] [D loss: 0.192315] [G loss: 0.401256]\n",
      "[Epoch 2/10] [Batch 1850/3750] [D loss: 0.247047] [G loss: 0.327307]\n",
      "[Epoch 2/10] [Batch 1900/3750] [D loss: 0.221910] [G loss: 0.402229]\n",
      "[Epoch 2/10] [Batch 1950/3750] [D loss: 0.185019] [G loss: 0.386685]\n",
      "[Epoch 2/10] [Batch 2000/3750] [D loss: 0.265954] [G loss: 0.342023]\n",
      "[Epoch 2/10] [Batch 2050/3750] [D loss: 0.252321] [G loss: 0.343563]\n",
      "[Epoch 2/10] [Batch 2100/3750] [D loss: 0.213428] [G loss: 0.366744]\n",
      "[Epoch 2/10] [Batch 2150/3750] [D loss: 0.207307] [G loss: 0.289375]\n",
      "[Epoch 2/10] [Batch 2200/3750] [D loss: 0.218201] [G loss: 0.405089]\n",
      "[Epoch 2/10] [Batch 2250/3750] [D loss: 0.210351] [G loss: 0.351157]\n",
      "[Epoch 2/10] [Batch 2300/3750] [D loss: 0.201594] [G loss: 0.400774]\n",
      "[Epoch 2/10] [Batch 2350/3750] [D loss: 0.258863] [G loss: 0.316567]\n",
      "[Epoch 2/10] [Batch 2400/3750] [D loss: 0.270317] [G loss: 0.274761]\n",
      "[Epoch 2/10] [Batch 2450/3750] [D loss: 0.220104] [G loss: 0.357141]\n",
      "[Epoch 2/10] [Batch 2500/3750] [D loss: 0.198302] [G loss: 0.398228]\n",
      "[Epoch 2/10] [Batch 2550/3750] [D loss: 0.235599] [G loss: 0.386187]\n",
      "[Epoch 2/10] [Batch 2600/3750] [D loss: 0.210156] [G loss: 0.382954]\n",
      "[Epoch 2/10] [Batch 2650/3750] [D loss: 0.239169] [G loss: 0.403441]\n",
      "[Epoch 2/10] [Batch 2700/3750] [D loss: 0.237994] [G loss: 0.332011]\n",
      "[Epoch 2/10] [Batch 2750/3750] [D loss: 0.209018] [G loss: 0.367223]\n",
      "[Epoch 2/10] [Batch 2800/3750] [D loss: 0.209029] [G loss: 0.325972]\n",
      "[Epoch 2/10] [Batch 2850/3750] [D loss: 0.238461] [G loss: 0.386625]\n",
      "[Epoch 2/10] [Batch 2900/3750] [D loss: 0.242181] [G loss: 0.302092]\n",
      "[Epoch 2/10] [Batch 2950/3750] [D loss: 0.250315] [G loss: 0.358878]\n",
      "[Epoch 2/10] [Batch 3000/3750] [D loss: 0.228989] [G loss: 0.364881]\n",
      "[Epoch 2/10] [Batch 3050/3750] [D loss: 0.232129] [G loss: 0.344414]\n",
      "[Epoch 2/10] [Batch 3100/3750] [D loss: 0.234856] [G loss: 0.395769]\n",
      "[Epoch 2/10] [Batch 3150/3750] [D loss: 0.202365] [G loss: 0.406494]\n",
      "[Epoch 2/10] [Batch 3200/3750] [D loss: 0.248023] [G loss: 0.337034]\n",
      "[Epoch 2/10] [Batch 3250/3750] [D loss: 0.225464] [G loss: 0.350041]\n",
      "[Epoch 2/10] [Batch 3300/3750] [D loss: 0.236926] [G loss: 0.344887]\n",
      "[Epoch 2/10] [Batch 3350/3750] [D loss: 0.244820] [G loss: 0.347465]\n",
      "[Epoch 2/10] [Batch 3400/3750] [D loss: 0.255962] [G loss: 0.351692]\n",
      "[Epoch 2/10] [Batch 3450/3750] [D loss: 0.237943] [G loss: 0.320399]\n",
      "[Epoch 2/10] [Batch 3500/3750] [D loss: 0.231191] [G loss: 0.328230]\n",
      "[Epoch 2/10] [Batch 3550/3750] [D loss: 0.206697] [G loss: 0.374350]\n",
      "[Epoch 2/10] [Batch 3600/3750] [D loss: 0.217118] [G loss: 0.366246]\n",
      "[Epoch 2/10] [Batch 3650/3750] [D loss: 0.230810] [G loss: 0.338035]\n",
      "[Epoch 2/10] [Batch 3700/3750] [D loss: 0.202979] [G loss: 0.351503]\n",
      "[Epoch 3/10] [Batch 0/3750] [D loss: 0.215771] [G loss: 0.405868]\n",
      "[Epoch 3/10] [Batch 50/3750] [D loss: 0.213485] [G loss: 0.379895]\n",
      "[Epoch 3/10] [Batch 100/3750] [D loss: 0.209649] [G loss: 0.333691]\n",
      "[Epoch 3/10] [Batch 150/3750] [D loss: 0.223511] [G loss: 0.400319]\n",
      "[Epoch 3/10] [Batch 200/3750] [D loss: 0.192973] [G loss: 0.378482]\n",
      "[Epoch 3/10] [Batch 250/3750] [D loss: 0.221742] [G loss: 0.384888]\n",
      "[Epoch 3/10] [Batch 300/3750] [D loss: 0.214824] [G loss: 0.378140]\n",
      "[Epoch 3/10] [Batch 350/3750] [D loss: 0.225894] [G loss: 0.323655]\n",
      "[Epoch 3/10] [Batch 400/3750] [D loss: 0.232247] [G loss: 0.381248]\n",
      "[Epoch 3/10] [Batch 450/3750] [D loss: 0.253320] [G loss: 0.339300]\n",
      "[Epoch 3/10] [Batch 500/3750] [D loss: 0.229516] [G loss: 0.408201]\n",
      "[Epoch 3/10] [Batch 550/3750] [D loss: 0.218073] [G loss: 0.375352]\n",
      "[Epoch 3/10] [Batch 600/3750] [D loss: 0.232740] [G loss: 0.365529]\n",
      "[Epoch 3/10] [Batch 650/3750] [D loss: 0.245844] [G loss: 0.353539]\n",
      "[Epoch 3/10] [Batch 700/3750] [D loss: 0.252451] [G loss: 0.388750]\n",
      "[Epoch 3/10] [Batch 750/3750] [D loss: 0.217989] [G loss: 0.403290]\n",
      "[Epoch 3/10] [Batch 800/3750] [D loss: 0.241068] [G loss: 0.347927]\n",
      "[Epoch 3/10] [Batch 850/3750] [D loss: 0.212858] [G loss: 0.407144]\n",
      "[Epoch 3/10] [Batch 900/3750] [D loss: 0.206778] [G loss: 0.378819]\n",
      "[Epoch 3/10] [Batch 950/3750] [D loss: 0.234939] [G loss: 0.367545]\n",
      "[Epoch 3/10] [Batch 1000/3750] [D loss: 0.257327] [G loss: 0.319084]\n",
      "[Epoch 3/10] [Batch 1050/3750] [D loss: 0.206131] [G loss: 0.346779]\n",
      "[Epoch 3/10] [Batch 1100/3750] [D loss: 0.230844] [G loss: 0.381549]\n",
      "[Epoch 3/10] [Batch 1150/3750] [D loss: 0.211360] [G loss: 0.333946]\n",
      "[Epoch 3/10] [Batch 1200/3750] [D loss: 0.196520] [G loss: 0.419539]\n",
      "[Epoch 3/10] [Batch 1250/3750] [D loss: 0.212471] [G loss: 0.388748]\n",
      "[Epoch 3/10] [Batch 1300/3750] [D loss: 0.207215] [G loss: 0.371771]\n",
      "[Epoch 3/10] [Batch 1350/3750] [D loss: 0.209274] [G loss: 0.364481]\n",
      "[Epoch 3/10] [Batch 1400/3750] [D loss: 0.234413] [G loss: 0.385075]\n",
      "[Epoch 3/10] [Batch 1450/3750] [D loss: 0.212355] [G loss: 0.403504]\n",
      "[Epoch 3/10] [Batch 1500/3750] [D loss: 0.213167] [G loss: 0.397367]\n",
      "[Epoch 3/10] [Batch 1550/3750] [D loss: 0.218145] [G loss: 0.328416]\n",
      "[Epoch 3/10] [Batch 1600/3750] [D loss: 0.226389] [G loss: 0.324619]\n",
      "[Epoch 3/10] [Batch 1650/3750] [D loss: 0.197593] [G loss: 0.373977]\n",
      "[Epoch 3/10] [Batch 1700/3750] [D loss: 0.233374] [G loss: 0.369255]\n",
      "[Epoch 3/10] [Batch 1750/3750] [D loss: 0.266975] [G loss: 0.346915]\n",
      "[Epoch 3/10] [Batch 1800/3750] [D loss: 0.235224] [G loss: 0.331307]\n",
      "[Epoch 3/10] [Batch 1850/3750] [D loss: 0.209078] [G loss: 0.378984]\n",
      "[Epoch 3/10] [Batch 1900/3750] [D loss: 0.202594] [G loss: 0.380586]\n",
      "[Epoch 3/10] [Batch 1950/3750] [D loss: 0.223935] [G loss: 0.406922]\n",
      "[Epoch 3/10] [Batch 2000/3750] [D loss: 0.235450] [G loss: 0.390543]\n",
      "[Epoch 3/10] [Batch 2050/3750] [D loss: 0.203591] [G loss: 0.391284]\n",
      "[Epoch 3/10] [Batch 2100/3750] [D loss: 0.177209] [G loss: 0.429517]\n",
      "[Epoch 3/10] [Batch 2150/3750] [D loss: 0.268481] [G loss: 0.294261]\n",
      "[Epoch 3/10] [Batch 2200/3750] [D loss: 0.213247] [G loss: 0.319763]\n",
      "[Epoch 3/10] [Batch 2250/3750] [D loss: 0.220986] [G loss: 0.395592]\n",
      "[Epoch 3/10] [Batch 2300/3750] [D loss: 0.275442] [G loss: 0.352873]\n",
      "[Epoch 3/10] [Batch 2350/3750] [D loss: 0.197394] [G loss: 0.439577]\n",
      "[Epoch 3/10] [Batch 2400/3750] [D loss: 0.222646] [G loss: 0.421961]\n",
      "[Epoch 3/10] [Batch 2450/3750] [D loss: 0.221520] [G loss: 0.425886]\n",
      "[Epoch 3/10] [Batch 2500/3750] [D loss: 0.273601] [G loss: 0.288190]\n",
      "[Epoch 3/10] [Batch 2550/3750] [D loss: 0.235570] [G loss: 0.356811]\n",
      "[Epoch 3/10] [Batch 2600/3750] [D loss: 0.212471] [G loss: 0.328823]\n",
      "[Epoch 3/10] [Batch 2650/3750] [D loss: 0.215253] [G loss: 0.392823]\n",
      "[Epoch 3/10] [Batch 2700/3750] [D loss: 0.227209] [G loss: 0.323869]\n",
      "[Epoch 3/10] [Batch 2750/3750] [D loss: 0.281273] [G loss: 0.268456]\n",
      "[Epoch 3/10] [Batch 2800/3750] [D loss: 0.239338] [G loss: 0.324295]\n",
      "[Epoch 3/10] [Batch 2850/3750] [D loss: 0.240907] [G loss: 0.333682]\n",
      "[Epoch 3/10] [Batch 2900/3750] [D loss: 0.251585] [G loss: 0.411732]\n",
      "[Epoch 3/10] [Batch 2950/3750] [D loss: 0.248884] [G loss: 0.305136]\n",
      "[Epoch 3/10] [Batch 3000/3750] [D loss: 0.241727] [G loss: 0.387948]\n",
      "[Epoch 3/10] [Batch 3050/3750] [D loss: 0.213151] [G loss: 0.373195]\n",
      "[Epoch 3/10] [Batch 3100/3750] [D loss: 0.264598] [G loss: 0.286800]\n",
      "[Epoch 3/10] [Batch 3150/3750] [D loss: 0.194505] [G loss: 0.335678]\n",
      "[Epoch 3/10] [Batch 3200/3750] [D loss: 0.245539] [G loss: 0.302597]\n",
      "[Epoch 3/10] [Batch 3250/3750] [D loss: 0.225503] [G loss: 0.402989]\n",
      "[Epoch 3/10] [Batch 3300/3750] [D loss: 0.172881] [G loss: 0.418939]\n",
      "[Epoch 3/10] [Batch 3350/3750] [D loss: 0.240906] [G loss: 0.342903]\n",
      "[Epoch 3/10] [Batch 3400/3750] [D loss: 0.226351] [G loss: 0.396866]\n",
      "[Epoch 3/10] [Batch 3450/3750] [D loss: 0.267136] [G loss: 0.322727]\n",
      "[Epoch 3/10] [Batch 3500/3750] [D loss: 0.198357] [G loss: 0.397597]\n",
      "[Epoch 3/10] [Batch 3550/3750] [D loss: 0.266610] [G loss: 0.331419]\n",
      "[Epoch 3/10] [Batch 3600/3750] [D loss: 0.231545] [G loss: 0.284437]\n",
      "[Epoch 3/10] [Batch 3650/3750] [D loss: 0.232680] [G loss: 0.344598]\n",
      "[Epoch 3/10] [Batch 3700/3750] [D loss: 0.228710] [G loss: 0.391185]\n",
      "[Epoch 4/10] [Batch 0/3750] [D loss: 0.214226] [G loss: 0.357871]\n",
      "[Epoch 4/10] [Batch 50/3750] [D loss: 0.237158] [G loss: 0.355446]\n",
      "[Epoch 4/10] [Batch 100/3750] [D loss: 0.179894] [G loss: 0.469680]\n",
      "[Epoch 4/10] [Batch 150/3750] [D loss: 0.227363] [G loss: 0.351214]\n",
      "[Epoch 4/10] [Batch 200/3750] [D loss: 0.199895] [G loss: 0.404002]\n",
      "[Epoch 4/10] [Batch 250/3750] [D loss: 0.231783] [G loss: 0.351022]\n",
      "[Epoch 4/10] [Batch 300/3750] [D loss: 0.232241] [G loss: 0.435721]\n",
      "[Epoch 4/10] [Batch 350/3750] [D loss: 0.222244] [G loss: 0.326238]\n",
      "[Epoch 4/10] [Batch 400/3750] [D loss: 0.252993] [G loss: 0.313218]\n",
      "[Epoch 4/10] [Batch 450/3750] [D loss: 0.206082] [G loss: 0.381217]\n",
      "[Epoch 4/10] [Batch 500/3750] [D loss: 0.231164] [G loss: 0.330113]\n",
      "[Epoch 4/10] [Batch 550/3750] [D loss: 0.205095] [G loss: 0.387992]\n",
      "[Epoch 4/10] [Batch 600/3750] [D loss: 0.192276] [G loss: 0.385321]\n",
      "[Epoch 4/10] [Batch 650/3750] [D loss: 0.193851] [G loss: 0.389432]\n",
      "[Epoch 4/10] [Batch 700/3750] [D loss: 0.227858] [G loss: 0.331368]\n",
      "[Epoch 4/10] [Batch 750/3750] [D loss: 0.206483] [G loss: 0.382427]\n",
      "[Epoch 4/10] [Batch 800/3750] [D loss: 0.239076] [G loss: 0.251718]\n",
      "[Epoch 4/10] [Batch 850/3750] [D loss: 0.230621] [G loss: 0.272265]\n",
      "[Epoch 4/10] [Batch 900/3750] [D loss: 0.261793] [G loss: 0.348897]\n",
      "[Epoch 4/10] [Batch 950/3750] [D loss: 0.216766] [G loss: 0.344857]\n",
      "[Epoch 4/10] [Batch 1000/3750] [D loss: 0.208386] [G loss: 0.366258]\n",
      "[Epoch 4/10] [Batch 1050/3750] [D loss: 0.228412] [G loss: 0.384651]\n",
      "[Epoch 4/10] [Batch 1100/3750] [D loss: 0.242999] [G loss: 0.399548]\n",
      "[Epoch 4/10] [Batch 1150/3750] [D loss: 0.258452] [G loss: 0.357759]\n",
      "[Epoch 4/10] [Batch 1200/3750] [D loss: 0.210495] [G loss: 0.404007]\n",
      "[Epoch 4/10] [Batch 1250/3750] [D loss: 0.189737] [G loss: 0.404805]\n",
      "[Epoch 4/10] [Batch 1300/3750] [D loss: 0.224837] [G loss: 0.332274]\n",
      "[Epoch 4/10] [Batch 1350/3750] [D loss: 0.200512] [G loss: 0.395596]\n",
      "[Epoch 4/10] [Batch 1400/3750] [D loss: 0.231904] [G loss: 0.319312]\n",
      "[Epoch 4/10] [Batch 1450/3750] [D loss: 0.216422] [G loss: 0.388885]\n",
      "[Epoch 4/10] [Batch 1500/3750] [D loss: 0.236380] [G loss: 0.343739]\n",
      "[Epoch 4/10] [Batch 1550/3750] [D loss: 0.284512] [G loss: 0.347126]\n",
      "[Epoch 4/10] [Batch 1600/3750] [D loss: 0.212920] [G loss: 0.357050]\n",
      "[Epoch 4/10] [Batch 1650/3750] [D loss: 0.256451] [G loss: 0.357180]\n",
      "[Epoch 4/10] [Batch 1700/3750] [D loss: 0.241889] [G loss: 0.405588]\n",
      "[Epoch 4/10] [Batch 1750/3750] [D loss: 0.195428] [G loss: 0.354501]\n",
      "[Epoch 4/10] [Batch 1800/3750] [D loss: 0.236105] [G loss: 0.364172]\n",
      "[Epoch 4/10] [Batch 1850/3750] [D loss: 0.238512] [G loss: 0.374669]\n",
      "[Epoch 4/10] [Batch 1900/3750] [D loss: 0.234488] [G loss: 0.307585]\n",
      "[Epoch 4/10] [Batch 1950/3750] [D loss: 0.174739] [G loss: 0.435332]\n",
      "[Epoch 4/10] [Batch 2000/3750] [D loss: 0.198554] [G loss: 0.351788]\n",
      "[Epoch 4/10] [Batch 2050/3750] [D loss: 0.233330] [G loss: 0.367045]\n",
      "[Epoch 4/10] [Batch 2100/3750] [D loss: 0.239818] [G loss: 0.336407]\n",
      "[Epoch 4/10] [Batch 2150/3750] [D loss: 0.227495] [G loss: 0.408533]\n",
      "[Epoch 4/10] [Batch 2200/3750] [D loss: 0.300552] [G loss: 0.272968]\n",
      "[Epoch 4/10] [Batch 2250/3750] [D loss: 0.258086] [G loss: 0.307208]\n",
      "[Epoch 4/10] [Batch 2300/3750] [D loss: 0.194853] [G loss: 0.389340]\n",
      "[Epoch 4/10] [Batch 2350/3750] [D loss: 0.211559] [G loss: 0.371680]\n",
      "[Epoch 4/10] [Batch 2400/3750] [D loss: 0.252265] [G loss: 0.303791]\n",
      "[Epoch 4/10] [Batch 2450/3750] [D loss: 0.233231] [G loss: 0.357284]\n",
      "[Epoch 4/10] [Batch 2500/3750] [D loss: 0.216659] [G loss: 0.361149]\n",
      "[Epoch 4/10] [Batch 2550/3750] [D loss: 0.232469] [G loss: 0.340469]\n",
      "[Epoch 4/10] [Batch 2600/3750] [D loss: 0.215986] [G loss: 0.372867]\n",
      "[Epoch 4/10] [Batch 2650/3750] [D loss: 0.236005] [G loss: 0.388247]\n",
      "[Epoch 4/10] [Batch 2700/3750] [D loss: 0.216917] [G loss: 0.338948]\n",
      "[Epoch 4/10] [Batch 2750/3750] [D loss: 0.209069] [G loss: 0.418563]\n",
      "[Epoch 4/10] [Batch 2800/3750] [D loss: 0.221907] [G loss: 0.377395]\n",
      "[Epoch 4/10] [Batch 2850/3750] [D loss: 0.192091] [G loss: 0.374383]\n",
      "[Epoch 4/10] [Batch 2900/3750] [D loss: 0.223656] [G loss: 0.372937]\n",
      "[Epoch 4/10] [Batch 2950/3750] [D loss: 0.222167] [G loss: 0.363433]\n",
      "[Epoch 4/10] [Batch 3000/3750] [D loss: 0.211300] [G loss: 0.327839]\n",
      "[Epoch 4/10] [Batch 3050/3750] [D loss: 0.239830] [G loss: 0.334762]\n",
      "[Epoch 4/10] [Batch 3100/3750] [D loss: 0.224963] [G loss: 0.371694]\n",
      "[Epoch 4/10] [Batch 3150/3750] [D loss: 0.236959] [G loss: 0.336553]\n",
      "[Epoch 4/10] [Batch 3200/3750] [D loss: 0.194140] [G loss: 0.410313]\n",
      "[Epoch 4/10] [Batch 3250/3750] [D loss: 0.225686] [G loss: 0.359722]\n",
      "[Epoch 4/10] [Batch 3300/3750] [D loss: 0.217970] [G loss: 0.399010]\n",
      "[Epoch 4/10] [Batch 3350/3750] [D loss: 0.212943] [G loss: 0.379157]\n",
      "[Epoch 4/10] [Batch 3400/3750] [D loss: 0.192910] [G loss: 0.379171]\n",
      "[Epoch 4/10] [Batch 3450/3750] [D loss: 0.231002] [G loss: 0.326771]\n",
      "[Epoch 4/10] [Batch 3500/3750] [D loss: 0.191812] [G loss: 0.374124]\n",
      "[Epoch 4/10] [Batch 3550/3750] [D loss: 0.199063] [G loss: 0.329712]\n",
      "[Epoch 4/10] [Batch 3600/3750] [D loss: 0.215708] [G loss: 0.363561]\n",
      "[Epoch 4/10] [Batch 3650/3750] [D loss: 0.202517] [G loss: 0.374639]\n",
      "[Epoch 4/10] [Batch 3700/3750] [D loss: 0.238892] [G loss: 0.369342]\n",
      "[Epoch 5/10] [Batch 0/3750] [D loss: 0.216049] [G loss: 0.363828]\n",
      "[Epoch 5/10] [Batch 50/3750] [D loss: 0.211821] [G loss: 0.324645]\n",
      "[Epoch 5/10] [Batch 100/3750] [D loss: 0.252926] [G loss: 0.387560]\n",
      "[Epoch 5/10] [Batch 150/3750] [D loss: 0.229332] [G loss: 0.329772]\n",
      "[Epoch 5/10] [Batch 200/3750] [D loss: 0.217245] [G loss: 0.363943]\n",
      "[Epoch 5/10] [Batch 250/3750] [D loss: 0.203951] [G loss: 0.327422]\n",
      "[Epoch 5/10] [Batch 300/3750] [D loss: 0.223397] [G loss: 0.339834]\n",
      "[Epoch 5/10] [Batch 350/3750] [D loss: 0.249321] [G loss: 0.354432]\n",
      "[Epoch 5/10] [Batch 400/3750] [D loss: 0.228396] [G loss: 0.325167]\n",
      "[Epoch 5/10] [Batch 450/3750] [D loss: 0.250488] [G loss: 0.330891]\n",
      "[Epoch 5/10] [Batch 500/3750] [D loss: 0.226021] [G loss: 0.386540]\n",
      "[Epoch 5/10] [Batch 550/3750] [D loss: 0.277271] [G loss: 0.310452]\n",
      "[Epoch 5/10] [Batch 600/3750] [D loss: 0.254570] [G loss: 0.344108]\n",
      "[Epoch 5/10] [Batch 650/3750] [D loss: 0.198452] [G loss: 0.353330]\n",
      "[Epoch 5/10] [Batch 700/3750] [D loss: 0.223561] [G loss: 0.337080]\n",
      "[Epoch 5/10] [Batch 750/3750] [D loss: 0.186921] [G loss: 0.435250]\n",
      "[Epoch 5/10] [Batch 800/3750] [D loss: 0.289736] [G loss: 0.310937]\n",
      "[Epoch 5/10] [Batch 850/3750] [D loss: 0.221931] [G loss: 0.423175]\n",
      "[Epoch 5/10] [Batch 900/3750] [D loss: 0.233458] [G loss: 0.301500]\n",
      "[Epoch 5/10] [Batch 950/3750] [D loss: 0.231515] [G loss: 0.383825]\n",
      "[Epoch 5/10] [Batch 1000/3750] [D loss: 0.238760] [G loss: 0.399351]\n",
      "[Epoch 5/10] [Batch 1050/3750] [D loss: 0.177298] [G loss: 0.467510]\n",
      "[Epoch 5/10] [Batch 1100/3750] [D loss: 0.224121] [G loss: 0.318757]\n",
      "[Epoch 5/10] [Batch 1150/3750] [D loss: 0.210776] [G loss: 0.376486]\n",
      "[Epoch 5/10] [Batch 1200/3750] [D loss: 0.252726] [G loss: 0.301597]\n",
      "[Epoch 5/10] [Batch 1250/3750] [D loss: 0.195421] [G loss: 0.397236]\n",
      "[Epoch 5/10] [Batch 1300/3750] [D loss: 0.218851] [G loss: 0.342864]\n",
      "[Epoch 5/10] [Batch 1350/3750] [D loss: 0.238430] [G loss: 0.385558]\n",
      "[Epoch 5/10] [Batch 1400/3750] [D loss: 0.226184] [G loss: 0.358026]\n",
      "[Epoch 5/10] [Batch 1450/3750] [D loss: 0.217684] [G loss: 0.396908]\n",
      "[Epoch 5/10] [Batch 1500/3750] [D loss: 0.243417] [G loss: 0.363269]\n",
      "[Epoch 5/10] [Batch 1550/3750] [D loss: 0.229395] [G loss: 0.320658]\n",
      "[Epoch 5/10] [Batch 1600/3750] [D loss: 0.185675] [G loss: 0.412462]\n",
      "[Epoch 5/10] [Batch 1650/3750] [D loss: 0.247736] [G loss: 0.342519]\n",
      "[Epoch 5/10] [Batch 1700/3750] [D loss: 0.262569] [G loss: 0.311563]\n",
      "[Epoch 5/10] [Batch 1750/3750] [D loss: 0.201279] [G loss: 0.372398]\n",
      "[Epoch 5/10] [Batch 1800/3750] [D loss: 0.239258] [G loss: 0.333509]\n",
      "[Epoch 5/10] [Batch 1850/3750] [D loss: 0.225388] [G loss: 0.384936]\n",
      "[Epoch 5/10] [Batch 1900/3750] [D loss: 0.222344] [G loss: 0.358459]\n",
      "[Epoch 5/10] [Batch 1950/3750] [D loss: 0.237649] [G loss: 0.337226]\n",
      "[Epoch 5/10] [Batch 2000/3750] [D loss: 0.208600] [G loss: 0.399864]\n",
      "[Epoch 5/10] [Batch 2050/3750] [D loss: 0.179080] [G loss: 0.448865]\n",
      "[Epoch 5/10] [Batch 2100/3750] [D loss: 0.188393] [G loss: 0.398293]\n",
      "[Epoch 5/10] [Batch 2150/3750] [D loss: 0.219329] [G loss: 0.324051]\n",
      "[Epoch 5/10] [Batch 2200/3750] [D loss: 0.207544] [G loss: 0.371788]\n",
      "[Epoch 5/10] [Batch 2250/3750] [D loss: 0.229558] [G loss: 0.345686]\n",
      "[Epoch 5/10] [Batch 2300/3750] [D loss: 0.165580] [G loss: 0.461770]\n",
      "[Epoch 5/10] [Batch 2350/3750] [D loss: 0.177207] [G loss: 0.407646]\n",
      "[Epoch 5/10] [Batch 2400/3750] [D loss: 0.224646] [G loss: 0.328589]\n",
      "[Epoch 5/10] [Batch 2450/3750] [D loss: 0.198749] [G loss: 0.408594]\n",
      "[Epoch 5/10] [Batch 2500/3750] [D loss: 0.228783] [G loss: 0.336604]\n",
      "[Epoch 5/10] [Batch 2550/3750] [D loss: 0.223582] [G loss: 0.335605]\n",
      "[Epoch 5/10] [Batch 2600/3750] [D loss: 0.205869] [G loss: 0.420315]\n",
      "[Epoch 5/10] [Batch 2650/3750] [D loss: 0.213516] [G loss: 0.390665]\n",
      "[Epoch 5/10] [Batch 2700/3750] [D loss: 0.223899] [G loss: 0.333516]\n",
      "[Epoch 5/10] [Batch 2750/3750] [D loss: 0.226240] [G loss: 0.289349]\n",
      "[Epoch 5/10] [Batch 2800/3750] [D loss: 0.227362] [G loss: 0.355181]\n",
      "[Epoch 5/10] [Batch 2850/3750] [D loss: 0.269700] [G loss: 0.356361]\n",
      "[Epoch 5/10] [Batch 2900/3750] [D loss: 0.230809] [G loss: 0.369294]\n",
      "[Epoch 5/10] [Batch 2950/3750] [D loss: 0.214347] [G loss: 0.375523]\n",
      "[Epoch 5/10] [Batch 3000/3750] [D loss: 0.213958] [G loss: 0.360677]\n",
      "[Epoch 5/10] [Batch 3050/3750] [D loss: 0.265404] [G loss: 0.287192]\n",
      "[Epoch 5/10] [Batch 3100/3750] [D loss: 0.209593] [G loss: 0.338968]\n",
      "[Epoch 5/10] [Batch 3150/3750] [D loss: 0.210815] [G loss: 0.382292]\n",
      "[Epoch 5/10] [Batch 3200/3750] [D loss: 0.235452] [G loss: 0.380938]\n",
      "[Epoch 5/10] [Batch 3250/3750] [D loss: 0.240597] [G loss: 0.338453]\n",
      "[Epoch 5/10] [Batch 3300/3750] [D loss: 0.215386] [G loss: 0.378560]\n",
      "[Epoch 5/10] [Batch 3350/3750] [D loss: 0.217898] [G loss: 0.351503]\n",
      "[Epoch 5/10] [Batch 3400/3750] [D loss: 0.285922] [G loss: 0.322551]\n",
      "[Epoch 5/10] [Batch 3450/3750] [D loss: 0.216915] [G loss: 0.353768]\n",
      "[Epoch 5/10] [Batch 3500/3750] [D loss: 0.264104] [G loss: 0.288751]\n",
      "[Epoch 5/10] [Batch 3550/3750] [D loss: 0.195535] [G loss: 0.374259]\n",
      "[Epoch 5/10] [Batch 3600/3750] [D loss: 0.212605] [G loss: 0.433677]\n",
      "[Epoch 5/10] [Batch 3650/3750] [D loss: 0.214040] [G loss: 0.371603]\n",
      "[Epoch 5/10] [Batch 3700/3750] [D loss: 0.228229] [G loss: 0.379712]\n",
      "[Epoch 6/10] [Batch 0/3750] [D loss: 0.260551] [G loss: 0.338159]\n",
      "[Epoch 6/10] [Batch 50/3750] [D loss: 0.194368] [G loss: 0.373550]\n",
      "[Epoch 6/10] [Batch 100/3750] [D loss: 0.222692] [G loss: 0.377337]\n",
      "[Epoch 6/10] [Batch 150/3750] [D loss: 0.238148] [G loss: 0.311345]\n",
      "[Epoch 6/10] [Batch 200/3750] [D loss: 0.264849] [G loss: 0.364041]\n",
      "[Epoch 6/10] [Batch 250/3750] [D loss: 0.229113] [G loss: 0.313743]\n",
      "[Epoch 6/10] [Batch 300/3750] [D loss: 0.237205] [G loss: 0.351761]\n",
      "[Epoch 6/10] [Batch 350/3750] [D loss: 0.218899] [G loss: 0.377435]\n",
      "[Epoch 6/10] [Batch 400/3750] [D loss: 0.220945] [G loss: 0.386224]\n",
      "[Epoch 6/10] [Batch 450/3750] [D loss: 0.193653] [G loss: 0.371660]\n",
      "[Epoch 6/10] [Batch 500/3750] [D loss: 0.192413] [G loss: 0.443043]\n",
      "[Epoch 6/10] [Batch 550/3750] [D loss: 0.216841] [G loss: 0.299389]\n",
      "[Epoch 6/10] [Batch 600/3750] [D loss: 0.216211] [G loss: 0.355739]\n",
      "[Epoch 6/10] [Batch 650/3750] [D loss: 0.269946] [G loss: 0.349314]\n",
      "[Epoch 6/10] [Batch 700/3750] [D loss: 0.227289] [G loss: 0.318250]\n",
      "[Epoch 6/10] [Batch 750/3750] [D loss: 0.221605] [G loss: 0.353601]\n",
      "[Epoch 6/10] [Batch 800/3750] [D loss: 0.224871] [G loss: 0.378770]\n",
      "[Epoch 6/10] [Batch 850/3750] [D loss: 0.264982] [G loss: 0.291106]\n",
      "[Epoch 6/10] [Batch 900/3750] [D loss: 0.258962] [G loss: 0.330308]\n",
      "[Epoch 6/10] [Batch 950/3750] [D loss: 0.213615] [G loss: 0.386872]\n",
      "[Epoch 6/10] [Batch 1000/3750] [D loss: 0.249440] [G loss: 0.385259]\n",
      "[Epoch 6/10] [Batch 1050/3750] [D loss: 0.176118] [G loss: 0.367071]\n",
      "[Epoch 6/10] [Batch 1100/3750] [D loss: 0.182755] [G loss: 0.389818]\n",
      "[Epoch 6/10] [Batch 1150/3750] [D loss: 0.182646] [G loss: 0.374786]\n",
      "[Epoch 6/10] [Batch 1200/3750] [D loss: 0.191828] [G loss: 0.404133]\n",
      "[Epoch 6/10] [Batch 1250/3750] [D loss: 0.220188] [G loss: 0.402453]\n",
      "[Epoch 6/10] [Batch 1300/3750] [D loss: 0.272723] [G loss: 0.309480]\n",
      "[Epoch 6/10] [Batch 1350/3750] [D loss: 0.210954] [G loss: 0.378966]\n",
      "[Epoch 6/10] [Batch 1400/3750] [D loss: 0.187700] [G loss: 0.370762]\n",
      "[Epoch 6/10] [Batch 1450/3750] [D loss: 0.252995] [G loss: 0.291941]\n",
      "[Epoch 6/10] [Batch 1500/3750] [D loss: 0.204195] [G loss: 0.396358]\n",
      "[Epoch 6/10] [Batch 1550/3750] [D loss: 0.215061] [G loss: 0.404003]\n",
      "[Epoch 6/10] [Batch 1600/3750] [D loss: 0.218340] [G loss: 0.336559]\n",
      "[Epoch 6/10] [Batch 1650/3750] [D loss: 0.224871] [G loss: 0.366814]\n",
      "[Epoch 6/10] [Batch 1700/3750] [D loss: 0.240487] [G loss: 0.392761]\n",
      "[Epoch 6/10] [Batch 1750/3750] [D loss: 0.219116] [G loss: 0.379725]\n",
      "[Epoch 6/10] [Batch 1800/3750] [D loss: 0.212413] [G loss: 0.373506]\n",
      "[Epoch 6/10] [Batch 1850/3750] [D loss: 0.250137] [G loss: 0.338602]\n",
      "[Epoch 6/10] [Batch 1900/3750] [D loss: 0.265256] [G loss: 0.313468]\n",
      "[Epoch 6/10] [Batch 1950/3750] [D loss: 0.201644] [G loss: 0.406077]\n",
      "[Epoch 6/10] [Batch 2000/3750] [D loss: 0.221368] [G loss: 0.358959]\n",
      "[Epoch 6/10] [Batch 2050/3750] [D loss: 0.173961] [G loss: 0.406445]\n",
      "[Epoch 6/10] [Batch 2100/3750] [D loss: 0.200248] [G loss: 0.411095]\n",
      "[Epoch 6/10] [Batch 2150/3750] [D loss: 0.224434] [G loss: 0.387708]\n",
      "[Epoch 6/10] [Batch 2200/3750] [D loss: 0.235098] [G loss: 0.364787]\n",
      "[Epoch 6/10] [Batch 2250/3750] [D loss: 0.221674] [G loss: 0.402277]\n",
      "[Epoch 6/10] [Batch 2300/3750] [D loss: 0.203111] [G loss: 0.414409]\n",
      "[Epoch 6/10] [Batch 2350/3750] [D loss: 0.210113] [G loss: 0.366556]\n",
      "[Epoch 6/10] [Batch 2400/3750] [D loss: 0.200119] [G loss: 0.408568]\n",
      "[Epoch 6/10] [Batch 2450/3750] [D loss: 0.204508] [G loss: 0.350816]\n",
      "[Epoch 6/10] [Batch 2500/3750] [D loss: 0.220711] [G loss: 0.467229]\n",
      "[Epoch 6/10] [Batch 2550/3750] [D loss: 0.211351] [G loss: 0.369196]\n",
      "[Epoch 6/10] [Batch 2600/3750] [D loss: 0.217019] [G loss: 0.329536]\n",
      "[Epoch 6/10] [Batch 2650/3750] [D loss: 0.241738] [G loss: 0.386840]\n",
      "[Epoch 6/10] [Batch 2700/3750] [D loss: 0.228013] [G loss: 0.311176]\n",
      "[Epoch 6/10] [Batch 2750/3750] [D loss: 0.242122] [G loss: 0.349241]\n",
      "[Epoch 6/10] [Batch 2800/3750] [D loss: 0.212632] [G loss: 0.464690]\n",
      "[Epoch 6/10] [Batch 2850/3750] [D loss: 0.265786] [G loss: 0.360035]\n",
      "[Epoch 6/10] [Batch 2900/3750] [D loss: 0.211649] [G loss: 0.418038]\n",
      "[Epoch 6/10] [Batch 2950/3750] [D loss: 0.198236] [G loss: 0.377194]\n",
      "[Epoch 6/10] [Batch 3000/3750] [D loss: 0.264301] [G loss: 0.292904]\n",
      "[Epoch 6/10] [Batch 3050/3750] [D loss: 0.266483] [G loss: 0.308061]\n",
      "[Epoch 6/10] [Batch 3100/3750] [D loss: 0.243201] [G loss: 0.381465]\n",
      "[Epoch 6/10] [Batch 3150/3750] [D loss: 0.204629] [G loss: 0.410525]\n",
      "[Epoch 6/10] [Batch 3200/3750] [D loss: 0.271506] [G loss: 0.363243]\n",
      "[Epoch 6/10] [Batch 3250/3750] [D loss: 0.225917] [G loss: 0.363879]\n",
      "[Epoch 6/10] [Batch 3300/3750] [D loss: 0.214597] [G loss: 0.366776]\n",
      "[Epoch 6/10] [Batch 3350/3750] [D loss: 0.215679] [G loss: 0.381200]\n",
      "[Epoch 6/10] [Batch 3400/3750] [D loss: 0.240485] [G loss: 0.325929]\n",
      "[Epoch 6/10] [Batch 3450/3750] [D loss: 0.192069] [G loss: 0.439576]\n",
      "[Epoch 6/10] [Batch 3500/3750] [D loss: 0.199617] [G loss: 0.443858]\n",
      "[Epoch 6/10] [Batch 3550/3750] [D loss: 0.196136] [G loss: 0.353979]\n",
      "[Epoch 6/10] [Batch 3600/3750] [D loss: 0.242805] [G loss: 0.372567]\n",
      "[Epoch 6/10] [Batch 3650/3750] [D loss: 0.228474] [G loss: 0.369130]\n",
      "[Epoch 6/10] [Batch 3700/3750] [D loss: 0.210360] [G loss: 0.348040]\n",
      "[Epoch 7/10] [Batch 0/3750] [D loss: 0.235133] [G loss: 0.336153]\n",
      "[Epoch 7/10] [Batch 50/3750] [D loss: 0.233784] [G loss: 0.371569]\n",
      "[Epoch 7/10] [Batch 100/3750] [D loss: 0.235391] [G loss: 0.324719]\n",
      "[Epoch 7/10] [Batch 150/3750] [D loss: 0.224971] [G loss: 0.362974]\n",
      "[Epoch 7/10] [Batch 200/3750] [D loss: 0.191796] [G loss: 0.443511]\n",
      "[Epoch 7/10] [Batch 250/3750] [D loss: 0.225297] [G loss: 0.368143]\n",
      "[Epoch 7/10] [Batch 300/3750] [D loss: 0.255047] [G loss: 0.308247]\n",
      "[Epoch 7/10] [Batch 350/3750] [D loss: 0.256856] [G loss: 0.323027]\n",
      "[Epoch 7/10] [Batch 400/3750] [D loss: 0.216688] [G loss: 0.380144]\n",
      "[Epoch 7/10] [Batch 450/3750] [D loss: 0.240019] [G loss: 0.386545]\n",
      "[Epoch 7/10] [Batch 500/3750] [D loss: 0.200714] [G loss: 0.418139]\n",
      "[Epoch 7/10] [Batch 550/3750] [D loss: 0.229398] [G loss: 0.369733]\n",
      "[Epoch 7/10] [Batch 600/3750] [D loss: 0.221875] [G loss: 0.405190]\n",
      "[Epoch 7/10] [Batch 650/3750] [D loss: 0.215571] [G loss: 0.386661]\n",
      "[Epoch 7/10] [Batch 700/3750] [D loss: 0.215194] [G loss: 0.356771]\n",
      "[Epoch 7/10] [Batch 750/3750] [D loss: 0.224365] [G loss: 0.419148]\n",
      "[Epoch 7/10] [Batch 800/3750] [D loss: 0.198232] [G loss: 0.419917]\n",
      "[Epoch 7/10] [Batch 850/3750] [D loss: 0.224299] [G loss: 0.346647]\n",
      "[Epoch 7/10] [Batch 900/3750] [D loss: 0.248383] [G loss: 0.390760]\n",
      "[Epoch 7/10] [Batch 950/3750] [D loss: 0.233874] [G loss: 0.352741]\n",
      "[Epoch 7/10] [Batch 1000/3750] [D loss: 0.248995] [G loss: 0.341765]\n",
      "[Epoch 7/10] [Batch 1050/3750] [D loss: 0.239177] [G loss: 0.411336]\n",
      "[Epoch 7/10] [Batch 1100/3750] [D loss: 0.168496] [G loss: 0.438546]\n",
      "[Epoch 7/10] [Batch 1150/3750] [D loss: 0.226562] [G loss: 0.346385]\n",
      "[Epoch 7/10] [Batch 1200/3750] [D loss: 0.269938] [G loss: 0.336703]\n",
      "[Epoch 7/10] [Batch 1250/3750] [D loss: 0.214030] [G loss: 0.337053]\n",
      "[Epoch 7/10] [Batch 1300/3750] [D loss: 0.193252] [G loss: 0.380501]\n",
      "[Epoch 7/10] [Batch 1350/3750] [D loss: 0.239195] [G loss: 0.347722]\n",
      "[Epoch 7/10] [Batch 1400/3750] [D loss: 0.216129] [G loss: 0.397746]\n",
      "[Epoch 7/10] [Batch 1450/3750] [D loss: 0.217079] [G loss: 0.312770]\n",
      "[Epoch 7/10] [Batch 1500/3750] [D loss: 0.211622] [G loss: 0.369276]\n",
      "[Epoch 7/10] [Batch 1550/3750] [D loss: 0.245611] [G loss: 0.349305]\n",
      "[Epoch 7/10] [Batch 1600/3750] [D loss: 0.209803] [G loss: 0.333717]\n",
      "[Epoch 7/10] [Batch 1650/3750] [D loss: 0.205835] [G loss: 0.414607]\n",
      "[Epoch 7/10] [Batch 1700/3750] [D loss: 0.260782] [G loss: 0.369093]\n",
      "[Epoch 7/10] [Batch 1750/3750] [D loss: 0.215470] [G loss: 0.340817]\n",
      "[Epoch 7/10] [Batch 1800/3750] [D loss: 0.189877] [G loss: 0.374613]\n",
      "[Epoch 7/10] [Batch 1850/3750] [D loss: 0.201038] [G loss: 0.351048]\n",
      "[Epoch 7/10] [Batch 1900/3750] [D loss: 0.210127] [G loss: 0.403494]\n",
      "[Epoch 7/10] [Batch 1950/3750] [D loss: 0.198774] [G loss: 0.388368]\n",
      "[Epoch 7/10] [Batch 2000/3750] [D loss: 0.174969] [G loss: 0.450215]\n",
      "[Epoch 7/10] [Batch 2050/3750] [D loss: 0.235611] [G loss: 0.334982]\n",
      "[Epoch 7/10] [Batch 2100/3750] [D loss: 0.168924] [G loss: 0.372993]\n",
      "[Epoch 7/10] [Batch 2150/3750] [D loss: 0.190341] [G loss: 0.372023]\n",
      "[Epoch 7/10] [Batch 2200/3750] [D loss: 0.237944] [G loss: 0.386952]\n",
      "[Epoch 7/10] [Batch 2250/3750] [D loss: 0.212629] [G loss: 0.373370]\n",
      "[Epoch 7/10] [Batch 2300/3750] [D loss: 0.219937] [G loss: 0.388532]\n",
      "[Epoch 7/10] [Batch 2350/3750] [D loss: 0.192041] [G loss: 0.365895]\n",
      "[Epoch 7/10] [Batch 2400/3750] [D loss: 0.170380] [G loss: 0.416057]\n",
      "[Epoch 7/10] [Batch 2450/3750] [D loss: 0.204988] [G loss: 0.370374]\n",
      "[Epoch 7/10] [Batch 2500/3750] [D loss: 0.201528] [G loss: 0.393488]\n",
      "[Epoch 7/10] [Batch 2550/3750] [D loss: 0.196905] [G loss: 0.441189]\n",
      "[Epoch 7/10] [Batch 2600/3750] [D loss: 0.247190] [G loss: 0.302836]\n",
      "[Epoch 7/10] [Batch 2650/3750] [D loss: 0.186268] [G loss: 0.428248]\n",
      "[Epoch 7/10] [Batch 2700/3750] [D loss: 0.255013] [G loss: 0.334085]\n",
      "[Epoch 7/10] [Batch 2750/3750] [D loss: 0.211334] [G loss: 0.351442]\n",
      "[Epoch 7/10] [Batch 2800/3750] [D loss: 0.226423] [G loss: 0.348890]\n",
      "[Epoch 7/10] [Batch 2850/3750] [D loss: 0.235978] [G loss: 0.401577]\n",
      "[Epoch 7/10] [Batch 2900/3750] [D loss: 0.217381] [G loss: 0.375172]\n",
      "[Epoch 7/10] [Batch 2950/3750] [D loss: 0.255872] [G loss: 0.367611]\n",
      "[Epoch 7/10] [Batch 3000/3750] [D loss: 0.232673] [G loss: 0.333921]\n",
      "[Epoch 7/10] [Batch 3050/3750] [D loss: 0.217245] [G loss: 0.364451]\n",
      "[Epoch 7/10] [Batch 3100/3750] [D loss: 0.177350] [G loss: 0.380347]\n",
      "[Epoch 7/10] [Batch 3150/3750] [D loss: 0.238008] [G loss: 0.393605]\n",
      "[Epoch 7/10] [Batch 3200/3750] [D loss: 0.209883] [G loss: 0.320289]\n",
      "[Epoch 7/10] [Batch 3250/3750] [D loss: 0.226587] [G loss: 0.333886]\n",
      "[Epoch 7/10] [Batch 3300/3750] [D loss: 0.212658] [G loss: 0.353520]\n",
      "[Epoch 7/10] [Batch 3350/3750] [D loss: 0.262839] [G loss: 0.313967]\n",
      "[Epoch 7/10] [Batch 3400/3750] [D loss: 0.189627] [G loss: 0.389666]\n",
      "[Epoch 7/10] [Batch 3450/3750] [D loss: 0.245326] [G loss: 0.371686]\n",
      "[Epoch 7/10] [Batch 3500/3750] [D loss: 0.181123] [G loss: 0.431891]\n",
      "[Epoch 7/10] [Batch 3550/3750] [D loss: 0.194641] [G loss: 0.390901]\n",
      "[Epoch 7/10] [Batch 3600/3750] [D loss: 0.206787] [G loss: 0.373096]\n",
      "[Epoch 7/10] [Batch 3650/3750] [D loss: 0.205557] [G loss: 0.443889]\n",
      "[Epoch 7/10] [Batch 3700/3750] [D loss: 0.267150] [G loss: 0.312178]\n",
      "[Epoch 8/10] [Batch 0/3750] [D loss: 0.245369] [G loss: 0.438729]\n",
      "[Epoch 8/10] [Batch 50/3750] [D loss: 0.179049] [G loss: 0.348265]\n",
      "[Epoch 8/10] [Batch 100/3750] [D loss: 0.219137] [G loss: 0.414201]\n",
      "[Epoch 8/10] [Batch 150/3750] [D loss: 0.247564] [G loss: 0.328019]\n",
      "[Epoch 8/10] [Batch 200/3750] [D loss: 0.204200] [G loss: 0.359271]\n",
      "[Epoch 8/10] [Batch 250/3750] [D loss: 0.188914] [G loss: 0.395810]\n",
      "[Epoch 8/10] [Batch 300/3750] [D loss: 0.216832] [G loss: 0.333951]\n",
      "[Epoch 8/10] [Batch 350/3750] [D loss: 0.246326] [G loss: 0.290558]\n",
      "[Epoch 8/10] [Batch 400/3750] [D loss: 0.266584] [G loss: 0.313972]\n",
      "[Epoch 8/10] [Batch 450/3750] [D loss: 0.202101] [G loss: 0.367759]\n",
      "[Epoch 8/10] [Batch 500/3750] [D loss: 0.223783] [G loss: 0.432662]\n",
      "[Epoch 8/10] [Batch 550/3750] [D loss: 0.240227] [G loss: 0.364412]\n",
      "[Epoch 8/10] [Batch 600/3750] [D loss: 0.217027] [G loss: 0.350427]\n",
      "[Epoch 8/10] [Batch 650/3750] [D loss: 0.202800] [G loss: 0.365348]\n",
      "[Epoch 8/10] [Batch 700/3750] [D loss: 0.238440] [G loss: 0.408680]\n",
      "[Epoch 8/10] [Batch 750/3750] [D loss: 0.231477] [G loss: 0.341688]\n",
      "[Epoch 8/10] [Batch 800/3750] [D loss: 0.237744] [G loss: 0.330399]\n",
      "[Epoch 8/10] [Batch 850/3750] [D loss: 0.250561] [G loss: 0.314342]\n",
      "[Epoch 8/10] [Batch 900/3750] [D loss: 0.237145] [G loss: 0.370773]\n",
      "[Epoch 8/10] [Batch 950/3750] [D loss: 0.235316] [G loss: 0.391227]\n",
      "[Epoch 8/10] [Batch 1000/3750] [D loss: 0.226950] [G loss: 0.354961]\n",
      "[Epoch 8/10] [Batch 1050/3750] [D loss: 0.257736] [G loss: 0.396643]\n",
      "[Epoch 8/10] [Batch 1100/3750] [D loss: 0.195261] [G loss: 0.412947]\n",
      "[Epoch 8/10] [Batch 1150/3750] [D loss: 0.215317] [G loss: 0.439236]\n",
      "[Epoch 8/10] [Batch 1200/3750] [D loss: 0.221847] [G loss: 0.337809]\n",
      "[Epoch 8/10] [Batch 1250/3750] [D loss: 0.178010] [G loss: 0.395670]\n",
      "[Epoch 8/10] [Batch 1300/3750] [D loss: 0.215969] [G loss: 0.428136]\n",
      "[Epoch 8/10] [Batch 1350/3750] [D loss: 0.244143] [G loss: 0.333890]\n",
      "[Epoch 8/10] [Batch 1400/3750] [D loss: 0.194666] [G loss: 0.395669]\n",
      "[Epoch 8/10] [Batch 1450/3750] [D loss: 0.208764] [G loss: 0.348165]\n",
      "[Epoch 8/10] [Batch 1500/3750] [D loss: 0.209808] [G loss: 0.368451]\n",
      "[Epoch 8/10] [Batch 1550/3750] [D loss: 0.217127] [G loss: 0.401409]\n",
      "[Epoch 8/10] [Batch 1600/3750] [D loss: 0.234650] [G loss: 0.388640]\n",
      "[Epoch 8/10] [Batch 1650/3750] [D loss: 0.222552] [G loss: 0.384465]\n",
      "[Epoch 8/10] [Batch 1700/3750] [D loss: 0.235035] [G loss: 0.341582]\n",
      "[Epoch 8/10] [Batch 1750/3750] [D loss: 0.238465] [G loss: 0.346419]\n",
      "[Epoch 8/10] [Batch 1800/3750] [D loss: 0.179789] [G loss: 0.403782]\n",
      "[Epoch 8/10] [Batch 1850/3750] [D loss: 0.273066] [G loss: 0.304963]\n",
      "[Epoch 8/10] [Batch 1900/3750] [D loss: 0.235514] [G loss: 0.387191]\n",
      "[Epoch 8/10] [Batch 1950/3750] [D loss: 0.195792] [G loss: 0.370552]\n",
      "[Epoch 8/10] [Batch 2000/3750] [D loss: 0.204730] [G loss: 0.417458]\n",
      "[Epoch 8/10] [Batch 2050/3750] [D loss: 0.257641] [G loss: 0.341318]\n",
      "[Epoch 8/10] [Batch 2100/3750] [D loss: 0.201973] [G loss: 0.374329]\n",
      "[Epoch 8/10] [Batch 2150/3750] [D loss: 0.269755] [G loss: 0.301938]\n",
      "[Epoch 8/10] [Batch 2200/3750] [D loss: 0.223037] [G loss: 0.361292]\n",
      "[Epoch 8/10] [Batch 2250/3750] [D loss: 0.214422] [G loss: 0.407625]\n",
      "[Epoch 8/10] [Batch 2300/3750] [D loss: 0.241819] [G loss: 0.279841]\n",
      "[Epoch 8/10] [Batch 2350/3750] [D loss: 0.153559] [G loss: 0.450073]\n",
      "[Epoch 8/10] [Batch 2400/3750] [D loss: 0.215333] [G loss: 0.367060]\n",
      "[Epoch 8/10] [Batch 2450/3750] [D loss: 0.204081] [G loss: 0.351543]\n",
      "[Epoch 8/10] [Batch 2500/3750] [D loss: 0.252812] [G loss: 0.307580]\n",
      "[Epoch 8/10] [Batch 2550/3750] [D loss: 0.230641] [G loss: 0.395133]\n",
      "[Epoch 8/10] [Batch 2600/3750] [D loss: 0.228237] [G loss: 0.320613]\n",
      "[Epoch 8/10] [Batch 2650/3750] [D loss: 0.241329] [G loss: 0.308243]\n",
      "[Epoch 8/10] [Batch 2700/3750] [D loss: 0.216380] [G loss: 0.326496]\n",
      "[Epoch 8/10] [Batch 2750/3750] [D loss: 0.263956] [G loss: 0.338984]\n",
      "[Epoch 8/10] [Batch 2800/3750] [D loss: 0.233463] [G loss: 0.367851]\n",
      "[Epoch 8/10] [Batch 2850/3750] [D loss: 0.201885] [G loss: 0.358640]\n",
      "[Epoch 8/10] [Batch 2900/3750] [D loss: 0.239810] [G loss: 0.333051]\n",
      "[Epoch 8/10] [Batch 2950/3750] [D loss: 0.203864] [G loss: 0.363617]\n",
      "[Epoch 8/10] [Batch 3000/3750] [D loss: 0.222289] [G loss: 0.412086]\n",
      "[Epoch 8/10] [Batch 3050/3750] [D loss: 0.187367] [G loss: 0.416006]\n",
      "[Epoch 8/10] [Batch 3100/3750] [D loss: 0.228413] [G loss: 0.338478]\n",
      "[Epoch 8/10] [Batch 3150/3750] [D loss: 0.174511] [G loss: 0.433047]\n",
      "[Epoch 8/10] [Batch 3200/3750] [D loss: 0.227150] [G loss: 0.337787]\n",
      "[Epoch 8/10] [Batch 3250/3750] [D loss: 0.219366] [G loss: 0.363003]\n",
      "[Epoch 8/10] [Batch 3300/3750] [D loss: 0.213256] [G loss: 0.383254]\n",
      "[Epoch 8/10] [Batch 3350/3750] [D loss: 0.234624] [G loss: 0.379309]\n",
      "[Epoch 8/10] [Batch 3400/3750] [D loss: 0.262338] [G loss: 0.353206]\n",
      "[Epoch 8/10] [Batch 3450/3750] [D loss: 0.201359] [G loss: 0.375948]\n",
      "[Epoch 8/10] [Batch 3500/3750] [D loss: 0.231322] [G loss: 0.326127]\n",
      "[Epoch 8/10] [Batch 3550/3750] [D loss: 0.189229] [G loss: 0.389361]\n",
      "[Epoch 8/10] [Batch 3600/3750] [D loss: 0.183949] [G loss: 0.403239]\n",
      "[Epoch 8/10] [Batch 3650/3750] [D loss: 0.198344] [G loss: 0.424890]\n",
      "[Epoch 8/10] [Batch 3700/3750] [D loss: 0.262664] [G loss: 0.332264]\n",
      "[Epoch 9/10] [Batch 0/3750] [D loss: 0.227845] [G loss: 0.402035]\n",
      "[Epoch 9/10] [Batch 50/3750] [D loss: 0.209821] [G loss: 0.392295]\n",
      "[Epoch 9/10] [Batch 100/3750] [D loss: 0.194628] [G loss: 0.348488]\n",
      "[Epoch 9/10] [Batch 150/3750] [D loss: 0.192264] [G loss: 0.376114]\n",
      "[Epoch 9/10] [Batch 200/3750] [D loss: 0.278972] [G loss: 0.256566]\n",
      "[Epoch 9/10] [Batch 250/3750] [D loss: 0.201829] [G loss: 0.321869]\n",
      "[Epoch 9/10] [Batch 300/3750] [D loss: 0.223054] [G loss: 0.397924]\n",
      "[Epoch 9/10] [Batch 350/3750] [D loss: 0.252551] [G loss: 0.285355]\n",
      "[Epoch 9/10] [Batch 400/3750] [D loss: 0.212474] [G loss: 0.399012]\n",
      "[Epoch 9/10] [Batch 450/3750] [D loss: 0.256431] [G loss: 0.317715]\n",
      "[Epoch 9/10] [Batch 500/3750] [D loss: 0.228694] [G loss: 0.350328]\n",
      "[Epoch 9/10] [Batch 550/3750] [D loss: 0.239153] [G loss: 0.364172]\n",
      "[Epoch 9/10] [Batch 600/3750] [D loss: 0.226873] [G loss: 0.329542]\n",
      "[Epoch 9/10] [Batch 650/3750] [D loss: 0.261277] [G loss: 0.319690]\n",
      "[Epoch 9/10] [Batch 700/3750] [D loss: 0.237427] [G loss: 0.346087]\n",
      "[Epoch 9/10] [Batch 750/3750] [D loss: 0.222115] [G loss: 0.339932]\n",
      "[Epoch 9/10] [Batch 800/3750] [D loss: 0.212185] [G loss: 0.392522]\n",
      "[Epoch 9/10] [Batch 850/3750] [D loss: 0.214900] [G loss: 0.423706]\n",
      "[Epoch 9/10] [Batch 900/3750] [D loss: 0.199784] [G loss: 0.384440]\n",
      "[Epoch 9/10] [Batch 950/3750] [D loss: 0.234013] [G loss: 0.327545]\n",
      "[Epoch 9/10] [Batch 1000/3750] [D loss: 0.254127] [G loss: 0.308283]\n",
      "[Epoch 9/10] [Batch 1050/3750] [D loss: 0.270047] [G loss: 0.353287]\n",
      "[Epoch 9/10] [Batch 1100/3750] [D loss: 0.214933] [G loss: 0.386269]\n",
      "[Epoch 9/10] [Batch 1150/3750] [D loss: 0.243970] [G loss: 0.335339]\n",
      "[Epoch 9/10] [Batch 1200/3750] [D loss: 0.263907] [G loss: 0.311835]\n",
      "[Epoch 9/10] [Batch 1250/3750] [D loss: 0.210141] [G loss: 0.370983]\n",
      "[Epoch 9/10] [Batch 1300/3750] [D loss: 0.221719] [G loss: 0.324735]\n",
      "[Epoch 9/10] [Batch 1350/3750] [D loss: 0.247592] [G loss: 0.301933]\n",
      "[Epoch 9/10] [Batch 1400/3750] [D loss: 0.249784] [G loss: 0.362322]\n",
      "[Epoch 9/10] [Batch 1450/3750] [D loss: 0.235960] [G loss: 0.357084]\n",
      "[Epoch 9/10] [Batch 1500/3750] [D loss: 0.190714] [G loss: 0.364055]\n",
      "[Epoch 9/10] [Batch 1550/3750] [D loss: 0.214377] [G loss: 0.360055]\n",
      "[Epoch 9/10] [Batch 1600/3750] [D loss: 0.230695] [G loss: 0.376007]\n",
      "[Epoch 9/10] [Batch 1650/3750] [D loss: 0.241619] [G loss: 0.307386]\n",
      "[Epoch 9/10] [Batch 1700/3750] [D loss: 0.236377] [G loss: 0.317124]\n",
      "[Epoch 9/10] [Batch 1750/3750] [D loss: 0.229113] [G loss: 0.379853]\n",
      "[Epoch 9/10] [Batch 1800/3750] [D loss: 0.191260] [G loss: 0.383101]\n",
      "[Epoch 9/10] [Batch 1850/3750] [D loss: 0.241368] [G loss: 0.384535]\n",
      "[Epoch 9/10] [Batch 1900/3750] [D loss: 0.229783] [G loss: 0.382687]\n",
      "[Epoch 9/10] [Batch 1950/3750] [D loss: 0.230363] [G loss: 0.348345]\n",
      "[Epoch 9/10] [Batch 2000/3750] [D loss: 0.259504] [G loss: 0.334736]\n",
      "[Epoch 9/10] [Batch 2050/3750] [D loss: 0.249097] [G loss: 0.303146]\n",
      "[Epoch 9/10] [Batch 2100/3750] [D loss: 0.234577] [G loss: 0.366422]\n",
      "[Epoch 9/10] [Batch 2150/3750] [D loss: 0.203067] [G loss: 0.418754]\n",
      "[Epoch 9/10] [Batch 2200/3750] [D loss: 0.213939] [G loss: 0.427815]\n",
      "[Epoch 9/10] [Batch 2250/3750] [D loss: 0.213862] [G loss: 0.368819]\n",
      "[Epoch 9/10] [Batch 2300/3750] [D loss: 0.239780] [G loss: 0.388840]\n",
      "[Epoch 9/10] [Batch 2350/3750] [D loss: 0.193371] [G loss: 0.409378]\n",
      "[Epoch 9/10] [Batch 2400/3750] [D loss: 0.219837] [G loss: 0.335480]\n",
      "[Epoch 9/10] [Batch 2450/3750] [D loss: 0.234764] [G loss: 0.405637]\n",
      "[Epoch 9/10] [Batch 2500/3750] [D loss: 0.209327] [G loss: 0.362047]\n",
      "[Epoch 9/10] [Batch 2550/3750] [D loss: 0.232176] [G loss: 0.299183]\n",
      "[Epoch 9/10] [Batch 2600/3750] [D loss: 0.250967] [G loss: 0.319684]\n",
      "[Epoch 9/10] [Batch 2650/3750] [D loss: 0.200756] [G loss: 0.384472]\n",
      "[Epoch 9/10] [Batch 2700/3750] [D loss: 0.226405] [G loss: 0.296346]\n",
      "[Epoch 9/10] [Batch 2750/3750] [D loss: 0.201661] [G loss: 0.375608]\n",
      "[Epoch 9/10] [Batch 2800/3750] [D loss: 0.258219] [G loss: 0.325902]\n",
      "[Epoch 9/10] [Batch 2850/3750] [D loss: 0.235624] [G loss: 0.344722]\n",
      "[Epoch 9/10] [Batch 2900/3750] [D loss: 0.251813] [G loss: 0.362824]\n",
      "[Epoch 9/10] [Batch 2950/3750] [D loss: 0.264227] [G loss: 0.301494]\n",
      "[Epoch 9/10] [Batch 3000/3750] [D loss: 0.246677] [G loss: 0.335124]\n",
      "[Epoch 9/10] [Batch 3050/3750] [D loss: 0.251243] [G loss: 0.353503]\n",
      "[Epoch 9/10] [Batch 3100/3750] [D loss: 0.277868] [G loss: 0.327091]\n",
      "[Epoch 9/10] [Batch 3150/3750] [D loss: 0.251284] [G loss: 0.368366]\n",
      "[Epoch 9/10] [Batch 3200/3750] [D loss: 0.189176] [G loss: 0.465988]\n",
      "[Epoch 9/10] [Batch 3250/3750] [D loss: 0.207800] [G loss: 0.352872]\n",
      "[Epoch 9/10] [Batch 3300/3750] [D loss: 0.193452] [G loss: 0.434426]\n",
      "[Epoch 9/10] [Batch 3350/3750] [D loss: 0.220224] [G loss: 0.385779]\n",
      "[Epoch 9/10] [Batch 3400/3750] [D loss: 0.253379] [G loss: 0.290619]\n",
      "[Epoch 9/10] [Batch 3450/3750] [D loss: 0.209895] [G loss: 0.387586]\n",
      "[Epoch 9/10] [Batch 3500/3750] [D loss: 0.200023] [G loss: 0.369480]\n",
      "[Epoch 9/10] [Batch 3550/3750] [D loss: 0.263063] [G loss: 0.297522]\n",
      "[Epoch 9/10] [Batch 3600/3750] [D loss: 0.237323] [G loss: 0.396202]\n",
      "[Epoch 9/10] [Batch 3650/3750] [D loss: 0.241004] [G loss: 0.319511]\n",
      "[Epoch 9/10] [Batch 3700/3750] [D loss: 0.213666] [G loss: 0.342370]\n"
     ]
    }
   ],
   "source": [
    "# ----------\n",
    "#  模型训练\n",
    "# ----------\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "\n",
    "        batch_size = imgs.shape[0]\n",
    "\n",
    "        # 数据标签，valid=1表示真实的图片，fake=0表示生成的图片\n",
    "        valid = jt.ones([batch_size, 1]).float32().stop_grad()\n",
    "        fake = jt.zeros([batch_size, 1]).float32().stop_grad()\n",
    "\n",
    "        # 真实图片及其类别\n",
    "        real_imgs = jt.array(imgs)\n",
    "        labels = jt.array(labels)\n",
    "\n",
    "        # -----------------\n",
    "        #  训练生成器\n",
    "        # -----------------\n",
    "\n",
    "        # 采样随机噪声和数字类别作为生成器输入\n",
    "        z = jt.array(np.random.normal(0, 1, (batch_size, latent_dim))).float32()\n",
    "        gen_labels = jt.array(np.random.randint(0, n_classes, batch_size)).float32()\n",
    "\n",
    "        # 生成一组图片\n",
    "        gen_imgs = generator(z, gen_labels)\n",
    "        # 损失函数衡量生成器欺骗判别器的能力，即希望判别器将生成图片分类为valid\n",
    "        validity = discriminator(gen_imgs, gen_labels)\n",
    "        g_loss = adversarial_loss(validity, valid)\n",
    "        g_loss.sync()\n",
    "        optimizer_G.step(g_loss)\n",
    "\n",
    "        # ---------------------\n",
    "        #  训练判别器\n",
    "        # ---------------------\n",
    "\n",
    "        validity_real = discriminator(real_imgs, labels)\n",
    "        # TODO(3): 使用adversarial_loss 计算计算真实类别的损失函数 d_real_loss\n",
    "        # Your code starts here\n",
    "        d_real_loss = adversarial_loss(validity_real, valid)\n",
    "        # Your code ends here\n",
    "\n",
    "        validity_fake = discriminator(gen_imgs.stop_grad(), gen_labels)\n",
    "        # TODO(4): 使用adversarial_loss 计算计算虚假类别的损失函数 d_fake_loss\n",
    "        # Your code starts here\n",
    "        d_fake_loss = adversarial_loss(validity_fake, fake)\n",
    "        # Your code ends here\n",
    "\n",
    "        # 总的判别器损失\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "        d_loss.sync()\n",
    "        optimizer_D.step(d_loss)\n",
    "        if i  % 50 == 0:\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                % (epoch, n_epochs, i, len(dataloader), d_loss.data.mean(), g_loss.data.mean())\n",
    "            )\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % sample_interval == 0:\n",
    "            sample_image(n_row=10, batches_done=batches_done)\n",
    "            generator.save(\"generator_last.pkl\")\n",
    "            discriminator.save(\"discriminator_last.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "generator.eval()\n",
    "discriminator.eval()\n",
    "generator.load('generator_last.pkl')\n",
    "discriminator.load('discriminator_last.pkl')\n",
    "\n",
    "number = \"2025403330\" #TODO(5): 写入你的学号（字符串类型）\n",
    "n_row = len(number)\n",
    "z = jt.array(np.random.normal(0, 1, (n_row, latent_dim))).float32().stop_grad()\n",
    "labels = jt.array(np.array([int(number[num]) for num in range(n_row)])).float32().stop_grad()\n",
    "gen_imgs = generator(z,labels)\n",
    "\n",
    "img_array = gen_imgs.data.transpose((1,2,0,3))[0].reshape((gen_imgs.shape[2], -1))\n",
    "min_=img_array.min()\n",
    "max_=img_array.max()\n",
    "img_array=(img_array-min_)/(max_-min_)*255\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img_array, cmap='gray')\n",
    "ax.axis('off')\n",
    "\n",
    "fig.patch.set_visible(False)\n",
    "plt.savefig('result.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
